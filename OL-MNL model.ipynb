{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e36b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.models import load_model\n",
    "import numpy as numpy\n",
    "import pandas as pd\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.initializers import GlorotNormal\n",
    "from tensorflow.keras.activations import gelu\n",
    "from keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Nadam\n",
    "\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = \"C:/Users/Administrator/Downloads/fav_train_data.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "directory_path = 'C:/Users/Administrator/Downloads/'\n",
    "\n",
    "\n",
    "#for MNL and for outer nest\n",
    "#training\n",
    "train_data_choice = directory_path + 'pav_adopt.npy'\n",
    "train_data_name1 = directory_path + 'gender.npy'\n",
    "train_data_name2 = directory_path + 'drv_exp.npy'\n",
    "train_data_name3 = directory_path + 'violation.npy'\n",
    "train_data_name4 = directory_path + 'wtp.npy'\n",
    "train_data_name5 = directory_path + 'benefit.npy'\n",
    "train_data_name6 = directory_path + 'barrier.npy'\n",
    "train_data_name7 = directory_path + 'safety.npy'\n",
    "train_data_name8 = directory_path + 'age_34.npy'\n",
    "# train_data_name9 = directory_path + 'age_44.npy'\n",
    "train_data_name10 = directory_path + 'age_406.npy'\n",
    "train_data_name11 = directory_path + 'age_60a.npy'\n",
    "train_data_name12 = directory_path + 'educ.npy'\n",
    "train_data_name13 = directory_path + 'income_5010.npy'\n",
    "# train_data_name14 = directory_path + 'income_50.npy'\n",
    "# train_data_name15 = directory_path + 'income_100.npy'\n",
    "train_data_name16 = directory_path + 'income_100a.npy'\n",
    "train_data_name17 = directory_path + 'household.npy'\n",
    "# train_data_name18 = directory_path + 'occu.npy'\n",
    "train_data_name19 = directory_path + 'ASC.npy'\n",
    "train_data_name20 = directory_path + 'NN.npy'\n",
    "train_data_name21 = directory_path + 'tauu.npy'\n",
    "choices_num = 5\n",
    "gender = data.iloc[:,5]\n",
    "age_34 = data.iloc[:,1]\n",
    "age_44 = data.iloc[:,2]\n",
    "age_60 = data.iloc[:,3]\n",
    "age_60a = data.iloc[:,4]\n",
    "income_25 = data.iloc[:,6]\n",
    "income_50 = data.iloc[:,7]\n",
    "income_100 = data.iloc[:,8]\n",
    "income_100a = data.iloc[:,9]\n",
    "licence = data.iloc[:,10]\n",
    "drv_exp = data.iloc[:,24]\n",
    "household = data.iloc[:,20]\n",
    "benefitfav = data.iloc[:,45]\n",
    "barrierfav = data.iloc[:,46]\n",
    "safetyfav = data.iloc[:,47]\n",
    "socialfav = data.iloc[:,48]\n",
    "occu_pvb = data.iloc[:,22]\n",
    "occu_govt = data.iloc[:,21]\n",
    "veh_time = data.iloc[:,25]\n",
    "educ = data.iloc[:,19]\n",
    "married = data.iloc[:,18]\n",
    "occu = data.iloc[:,23]\n",
    "violations = data.iloc[:,13]\n",
    "accident = data.iloc[:,11]\n",
    "four_w = data.iloc[:,12]\n",
    "veh_cost= data.iloc[:,26]\n",
    "humanfav = data.iloc[:,44]\n",
    "income_251 = data.iloc[:,77]\n",
    "age_406 = data.iloc[:,76]\n",
    "income_5010 = data.iloc[:,80]\n",
    "wrk_rm =data.iloc[:,36]\n",
    "new_veh_cost =data.iloc[:,27]\n",
    "online_use =data.iloc[:,31]\n",
    "wtp =data.iloc[:,32]\n",
    "social =data.iloc[:,33]\n",
    "veh_cost1015 =data.iloc[:,30]\n",
    "benefit =data.iloc[:,16]\n",
    "barrier =data.iloc[:,17]\n",
    "safety =data.iloc[:,15]\n",
    "\n",
    "choice = data.iloc[:,0]\n",
    "Zeros = np.zeros(choice.size)\n",
    "ones = np.ones(choice.size)\n",
    "choice1 = choice == 1\n",
    "choice2 = choice == 2\n",
    "choice3 = choice == 3\n",
    "choice4 = choice == 4\n",
    "choice5 = choice == 5\n",
    "#RPdataset\n",
    "#Ordinal\n",
    "train_data = np.array([[choice1], [choice2],[choice3],[choice4],[choice5]])\n",
    "train_data = np.swapaxes(train_data,0,2)\n",
    "np.save(train_data_choice, np.array(train_data, dtype=np.float32))\n",
    "train_data1 = np.array([[gender] ])\n",
    "train_data1 = np.swapaxes(train_data1,0,2)\n",
    "np.save(train_data_name1, np.array(train_data1, dtype=np.float32))\n",
    "train_data2 = np.array([[drv_exp] ])\n",
    "train_data2 = np.swapaxes(train_data2,0,2)\n",
    "np.save(train_data_name2, np.array(train_data2, dtype=np.float32))\n",
    "train_data3 = np.array([[violations] ])\n",
    "train_data3 = np.swapaxes(train_data3,0,2)\n",
    "np.save(train_data_name3, np.array(train_data3, dtype=np.float32))\n",
    "train_data4 = np.array([[wtp] ])\n",
    "train_data4 = np.swapaxes(train_data4,0,2)\n",
    "np.save(train_data_name4, np.array(train_data4, dtype=np.float32))\n",
    "train_data5 = np.array([[benefit] ])\n",
    "train_data5 = np.swapaxes(train_data5,0,2)\n",
    "np.save(train_data_name5, np.array(train_data5, dtype=np.float32))\n",
    "\n",
    "train_data6 = np.array([[barrier] ])\n",
    "train_data6 = np.swapaxes(train_data6,0,2)\n",
    "np.save(train_data_name6, np.array(train_data6, dtype=np.float32))\n",
    "train_data7 = np.array([[safety] ])\n",
    "train_data7 = np.swapaxes(train_data7,0,2)\n",
    "np.save(train_data_name7, np.array(train_data7, dtype=np.float32))\n",
    "train_data8 = np.array([[age_34] ])\n",
    "train_data8 = np.swapaxes(train_data8,0,2)\n",
    "np.save(train_data_name8, np.array(train_data8, dtype=np.float32))\n",
    "# train_data9 = np.array([[age_44] ])\n",
    "# train_data9 = np.swapaxes(train_data9,0,2)\n",
    "# np.save(train_data_name9, np.array(train_data9, dtype=np.float32))\n",
    "train_data10 = np.array([[age_406] ])\n",
    "train_data10 = np.swapaxes(train_data10,0,2)\n",
    "np.save(train_data_name10, np.array(train_data10, dtype=np.float32))\n",
    "train_data11 = np.array([[age_60a] ])\n",
    "train_data11 = np.swapaxes(train_data11,0,2)\n",
    "np.save(train_data_name11, np.array(train_data11, dtype=np.float32))\n",
    "train_data12 = np.array([[educ] ])\n",
    "train_data12 = np.swapaxes(train_data12,0,2)\n",
    "np.save(train_data_name12, np.array(train_data12, dtype=np.float32))\n",
    "train_data13 = np.array([[income_5010] ])\n",
    "train_data13 = np.swapaxes(train_data13,0,2)\n",
    "np.save(train_data_name13, np.array(train_data13, dtype=np.float32))\n",
    "# train_data14 = np.array([[income_50] ])\n",
    "# train_data14 = np.swapaxes(train_data14,0,2)\n",
    "# np.save(train_data_name14, np.array(train_data14, dtype=np.float32))\n",
    "# train_data15 = np.array([[income_100] ])\n",
    "# train_data15 = np.swapaxes(train_data15,0,2)\n",
    "# np.save(train_data_name15, np.array(train_data15, dtype=np.float32))\n",
    "train_data16 = np.array([[income_100a] ])\n",
    "train_data16 = np.swapaxes(train_data16,0,2)\n",
    "np.save(train_data_name16, np.array(train_data16, dtype=np.float32))\n",
    "train_data17 = np.array([[household] ])\n",
    "train_data17 = np.swapaxes(train_data17,0,2)\n",
    "np.save(train_data_name17, np.array(train_data17, dtype=np.float32))\n",
    "# train_data18 = np.array([[occu] ])\n",
    "# train_data18 = np.swapaxes(train_data18,0,2)\n",
    "# np.save(train_data_name18, np.array(train_data18, dtype=np.float32))\n",
    "\n",
    "train_data19 = np.array([[ones]])\n",
    "train_data19 = np.swapaxes(train_data19,0,2)\n",
    "np.save(train_data_name19, np.array(train_data19, dtype=np.float32))\n",
    "train_data21 = np.array([[ones]])\n",
    "train_data21 = np.swapaxes(train_data21,0,2)\n",
    "np.save(train_data_name21, np.array(train_data21, dtype=np.float32))\n",
    "#DNN\n",
    "train_data20 = np.array([[licence,accident,four_w,veh_cost,married,occu_pvb,occu,social], [Zeros,Zeros,Zeros,Zeros,Zeros,Zeros,Zeros,Zeros]])\n",
    "train_data20 = np.swapaxes(train_data20,0,2)\n",
    "np.save(train_data_name20, np.array(train_data20, dtype=np.float32))\n",
    "\n",
    "# data = np.loadtxt('/content/Data.dat',skiprows = 1)\n",
    "\n",
    "\n",
    "#validation\n",
    "# Validation data\n",
    "file_path_val = \"C:/Users/Administrator/Downloads/fav_valid_data.csv\"\n",
    "dataV = pd.read_csv(file_path_val)\n",
    "directory_path = 'C:/Users/Administrator/Downloads/'\n",
    "\n",
    "train_data_choiceV = directory_path + 'choiceV.npy'\n",
    "train_data_name1V = directory_path + 'genderV.npy'\n",
    "train_data_name2V = directory_path + 'drv_expV.npy'\n",
    "train_data_name3V = directory_path + 'violationV.npy'\n",
    "train_data_name4V = directory_path + 'wtpV.npy'\n",
    "train_data_name5V = directory_path + 'benefitV.npy'\n",
    "train_data_name6V = directory_path + 'barrierV.npy'\n",
    "train_data_name7V = directory_path + 'safetyV.npy'\n",
    "train_data_name8V = directory_path + 'age_34V.npy'\n",
    "# train_data_name9V = directory_path + 'age_44V.npy'\n",
    "train_data_name10V = directory_path + 'age_406V.npy'\n",
    "train_data_name11V = directory_path + 'age_60aV.npy'\n",
    "train_data_name12V = directory_path + 'educV.npy'\n",
    "train_data_name13V = directory_path + 'income_5010V.npy'\n",
    "# train_data_name14V = directory_path + 'income_50V.npy'\n",
    "# train_data_name15V = directory_path + 'income_100V.npy'\n",
    "train_data_name16V = directory_path + 'income_100aV.npy'\n",
    "train_data_name17V = directory_path + 'householdV.npy'\n",
    "# train_data_name18V = directory_path + 'occuV.npy'\n",
    "train_data_name19V = directory_path + 'ASCV.npy'\n",
    "train_data_name20V = directory_path + 'NNV.npy'\n",
    "train_data_name21V = directory_path + 'tauuV.npy'\n",
    "\n",
    "choices_numV = 5\n",
    "genderV = dataV.iloc[:, 5]\n",
    "age_34V = dataV.iloc[:, 1]\n",
    "age_44V = dataV.iloc[:, 2]\n",
    "age_60V = dataV.iloc[:, 3]\n",
    "age_60aV = dataV.iloc[:, 4]\n",
    "income_25V = dataV.iloc[:, 6]\n",
    "income_50V = dataV.iloc[:, 7]\n",
    "income_100V = dataV.iloc[:, 8]\n",
    "income_100aV = dataV.iloc[:, 9]\n",
    "licenceV = dataV.iloc[:, 10]\n",
    "drv_expV = dataV.iloc[:, 24]\n",
    "householdV = dataV.iloc[:, 20]\n",
    "benefitfavV = dataV.iloc[:, 45]\n",
    "barrierfavV = dataV.iloc[:, 46]\n",
    "safetyfavV = dataV.iloc[:, 47]\n",
    "socialfavV = dataV.iloc[:, 48]\n",
    "occu_pvbV = dataV.iloc[:, 22]\n",
    "occu_govtV = dataV.iloc[:, 21]\n",
    "veh_timeV = dataV.iloc[:, 25]\n",
    "wrk_rmV =dataV.iloc[:,36]\n",
    "educV = dataV.iloc[:, 19]\n",
    "marriedV = dataV.iloc[:, 18]\n",
    "violationsV = dataV.iloc[:,13]\n",
    "accidentV = dataV.iloc[:,11]\n",
    "four_wV = dataV.iloc[:,12]\n",
    "veh_costV= dataV.iloc[:,26]\n",
    "new_veh_costV= dataV.iloc[:,27]\n",
    "occuV = dataV.iloc[:,23]\n",
    "humanfavV = dataV.iloc[:,44]\n",
    "online_useV = dataV.iloc[:,31]\n",
    "wtpV = dataV.iloc[:,32]\n",
    "veh_cost1015V =dataV.iloc[:,30]\n",
    "choiceV = dataV.iloc[:, 0]\n",
    "income_251V = dataV.iloc[:,77]\n",
    "age_406V = dataV.iloc[:,76]\n",
    "income_5010V = dataV.iloc[:,79]\n",
    "benefitV =dataV.iloc[:,16]\n",
    "barrierV =dataV.iloc[:,17]\n",
    "safetyV =dataV.iloc[:,15]\n",
    "socialV =dataV.iloc[:,33]\n",
    "\n",
    "ZerosV = np.zeros(choiceV.size)\n",
    "onesV = np.ones(choiceV.size)\n",
    "choice1V = choiceV == 1\n",
    "choice2V = choiceV == 2\n",
    "choice3V = choiceV == 3\n",
    "choice4V = choiceV == 4\n",
    "choice5V = choiceV == 5\n",
    "\n",
    "# RPdataset\n",
    "# Ordinal\n",
    "train_dataV = np.array([[choice1V], [choice2V], [choice3V], [choice4V], [choice5V]])\n",
    "train_dataV = np.swapaxes(train_dataV, 0, 2)\n",
    "np.save(train_data_choiceV, np.array(train_dataV, dtype=np.float32))\n",
    "train_data1V = np.array([[genderV]])\n",
    "train_data1V = np.swapaxes(train_data1V, 0, 2)\n",
    "np.save(train_data_name1V, np.array(train_data1V, dtype=np.float32))\n",
    "train_data2V = np.array([[drv_expV]])\n",
    "train_data2V = np.swapaxes(train_data2V, 0, 2)\n",
    "np.save(train_data_name2V, np.array(train_data2V, dtype=np.float32))\n",
    "train_data3V = np.array([[violationsV]])\n",
    "train_data3V = np.swapaxes(train_data3V, 0, 2)\n",
    "np.save(train_data_name3V, np.array(train_data3V, dtype=np.float32))\n",
    "train_data4V = np.array([[wtpV]])\n",
    "train_data4V = np.swapaxes(train_data4V, 0, 2)\n",
    "np.save(train_data_name4V, np.array(train_data4V, dtype=np.float32))\n",
    "train_data5V = np.array([[benefitV]])\n",
    "train_data5V = np.swapaxes(train_data5V, 0, 2)\n",
    "np.save(train_data_name5V, np.array(train_data5V, dtype=np.float32))\n",
    "train_data6V = np.array([[barrierV]])\n",
    "train_data6V = np.swapaxes(train_data6V, 0, 2)\n",
    "np.save(train_data_name6V, np.array(train_data6V, dtype=np.float32))\n",
    "train_data7V = np.array([[safetyV]])\n",
    "train_data7V = np.swapaxes(train_data7V, 0, 2)\n",
    "np.save(train_data_name7V, np.array(train_data7V, dtype=np.float32))\n",
    "train_data8V = np.array([[age_34V]])\n",
    "train_data8V = np.swapaxes(train_data8V, 0, 2)\n",
    "np.save(train_data_name8V, np.array(train_data8V, dtype=np.float32))\n",
    "# train_data9V = np.array([[age_44V]])\n",
    "# train_data9V = np.swapaxes(train_data9V, 0, 2)\n",
    "# np.save(train_data_name9V, np.array(train_data9V, dtype=np.float32))\n",
    "train_data10V = np.array([[age_406V]])\n",
    "train_data10V = np.swapaxes(train_data10V, 0, 2)\n",
    "np.save(train_data_name10V, np.array(train_data10V, dtype=np.float32))\n",
    "train_data11V = np.array([[age_60aV]])\n",
    "train_data11V = np.swapaxes(train_data11V, 0, 2)\n",
    "np.save(train_data_name11V, np.array(train_data11V, dtype=np.float32))\n",
    "train_data12V = np.array([[educV]])\n",
    "train_data12V = np.swapaxes(train_data12V, 0, 2)\n",
    "np.save(train_data_name12V, np.array(train_data12V, dtype=np.float32))\n",
    "train_data13V = np.array([[income_5010V]])\n",
    "train_data13V = np.swapaxes(train_data13V, 0, 2)\n",
    "np.save(train_data_name13V, np.array(train_data13V, dtype=np.float32))\n",
    "# train_data14V = np.array([[income_50V]])\n",
    "# train_data14V = np.swapaxes(train_data14V, 0, 2)\n",
    "# np.save(train_data_name14V, np.array(train_data14V, dtype=np.float32))\n",
    "# train_data15V = np.array([[income_100V]])\n",
    "# train_data15V = np.swapaxes(train_data15V, 0, 2)\n",
    "# np.save(train_data_name15V, np.array(train_data15V, dtype=np.float32))\n",
    "train_data16V = np.array([[income_100aV]])\n",
    "train_data16V = np.swapaxes(train_data16V, 0, 2)\n",
    "np.save(train_data_name16V, np.array(train_data16V, dtype=np.float32))\n",
    "train_data17V = np.array([[householdV]])\n",
    "train_data17V = np.swapaxes(train_data17V, 0, 2)\n",
    "np.save(train_data_name17V, np.array(train_data17V, dtype=np.float32))\n",
    "# train_data18V = np.array([[occuV]])\n",
    "# train_data18V = np.swapaxes(train_data18V, 0, 2)\n",
    "# np.save(train_data_name18V, np.array(train_data18V, dtype=np.float32))\n",
    "train_data19V = np.array([[onesV]])\n",
    "train_data19V = np.swapaxes(train_data19V, 0, 2)\n",
    "np.save(train_data_name19V, np.array(train_data19V, dtype=np.float32))\n",
    "train_data21V = np.array([[onesV]])\n",
    "train_data21V = np.swapaxes(train_data21V, 0, 2)\n",
    "np.save(train_data_name21V, np.array(train_data21V, dtype=np.float32))\n",
    "train_data20V = np.array([[licenceV,accidentV,four_wV,veh_costV,marriedV,occu_pvbV,occuV,socialV], [ZerosV,ZerosV,ZerosV,ZerosV,ZerosV, ZerosV,ZerosV,ZerosV]])\n",
    "train_data20V = np.swapaxes(train_data20V, 0, 2)\n",
    "np.save(train_data_name20V, np.array(train_data20V, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8c10e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.constraints import Constraint\n",
    "import keras.backend as K\n",
    "class Between(Constraint):\n",
    "    def __init__(self, min_value, max_value):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "    def __call__(self, w):\n",
    "        return tf.clip_by_value(w, self.min_value, self.max_value)\n",
    "    def get_config(self):\n",
    "        return {'min_value': self.min_value,\n",
    "                'max_value': self.max_value}from keras.constraints import Constraint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcc106f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten, Concatenate\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from tensorflow.keras.initializers import HeNormal\n",
    "import tensorflow as tf\n",
    "from keras.constraints import non_neg\n",
    "from tensorflow.keras.constraints import NonNeg\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import LeakyReLU\n",
    "#Repeat Results\n",
    "# def set_seed(seed=42):\n",
    "#     np.random.seed(seed)\n",
    "#     tf.random.set_seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# set_seed()\n",
    "l2_reg = l2(0.0001)\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('checkpoint.keras', monitor='loss',\n",
    "                                                      save_best_only=True,verbose=2)\n",
    "layer1 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='gendera',\n",
    "                  kernel_initializer=tf.keras.initializers.constant(0.04), use_bias=False,trainable=True)\n",
    "layer2 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='drv_expa',\n",
    "                  kernel_initializer=tf.keras.initializers.constant(0.13),use_bias=False,trainable=True)\n",
    "layer3 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='violationa',\n",
    "                  kernel_initializer=tf.keras.initializers.constant(0.17),use_bias=False,trainable=True)\n",
    "layer4 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='wtpa',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.20),use_bias=False,trainable=True)\n",
    "layer5 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='benefita',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.43),use_bias=False,trainable=True,kernel_constraint=NonNeg())\n",
    "layer6 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='barriera',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.30),use_bias=False,trainable=True)\n",
    "layer7 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='safetya',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.35),use_bias=False,trainable=True)\n",
    "layer8 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='age_34a',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.40),use_bias=False,trainable=True)\n",
    "# layer9 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='age_44a',\n",
    "#                   kernel_initializer=tf.keras.initializers.constant(0),use_bias=False,trainable=True)\n",
    "layer10 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='age_406aa',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.45),use_bias=False,trainable=True)\n",
    "layer11 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='age_60aaa',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.50),use_bias=False,trainable=True)\n",
    "layer12 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='educa',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.55),use_bias=False,trainable=True)\n",
    "layer13 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='income_5010a',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.60),use_bias=False,trainable=True,kernel_constraint=NonNeg())\n",
    "# layer14 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='income_50a',\n",
    "#                   kernel_initializer=tf.keras.initializers.constant(0),use_bias=False,trainable=True)\n",
    "# layer15 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='income_100aa',\n",
    "#                   kernel_initializer=tf.keras.initializers.constant(0),use_bias=False,trainable=True,kernel_constraint=NonNeg())\n",
    "layer16 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='income_100aaa',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.65),use_bias=False,trainable=True,kernel_constraint=NonNeg())\n",
    "layer17 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='householda',\n",
    "                  kernel_initializer=tf.keras.initializers.constant(0.23),use_bias=False,trainable=True)\n",
    "# layer18 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='occua',\n",
    "#                   kernel_initializer=tf.keras.initializers.constant(0.12),use_bias=False,trainable=True)\n",
    "\n",
    "\n",
    "layer19 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='ASCa1',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(-0.070),use_bias=False,trainable=True)\n",
    "layertau1 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='ttau1a',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.75),kernel_constraint=Between(0,5),\n",
    "                   use_bias=False,trainable=True)\n",
    "# layertau2 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='ttau2a',\n",
    "#                   kernel_initializer=GlorotNormal(),kernel_constraint=Between(0,5),\n",
    "#                  use_bias=False,trainable=True)\n",
    "layertau3 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='ttau3a',\n",
    "                  kernel_initializer= tf.keras.initializers.constant(0.85),kernel_constraint=Between(0,5),\n",
    "                  use_bias=False,trainable=True)\n",
    "# layertau4 = Conv2D(filters=1, kernel_size=[1,1], strides=(1,1), padding='valid', name='ttau4a',\n",
    "#                   kernel_initializer=GlorotNormal(),kernel_constraint=Between(0,5),\n",
    "#                   use_bias=False,trainable=True, kernel_regularizer=l2_reg)\n",
    "#threshold\n",
    "tau11 = Input((1,1,1), name = 'ta11')\n",
    "tau111 = layertau1(tau11)\n",
    "tau1111= Reshape([1], name='ta1') (tau111)\n",
    "# tau22 = Input((1,1,1), name = 'ta22')\n",
    "# tau222 = layertau2(tau22)\n",
    "# tau2222 = Reshape([1], name='ta2') (tau222)\n",
    "tau33 = Input((1,1,1), name = 'ta33')\n",
    "tau333 = layertau3(tau33)\n",
    "tau3333 = Reshape([1], name='ta3') (tau333)\n",
    "# tau44 = Input((1,1,1), name = 'ta44')\n",
    "# tau444 = layertau4(tau44)\n",
    "# tau4444 = Reshape([1], name='ta4') (tau444)\n",
    "tau1 = -(tau1111)-(tau3333)\n",
    "tau2 = -tau1111\n",
    "tau3 = tau1111\n",
    "tau4 = tau1111 + tau3333\n",
    "#defining parametrheterogeneity\n",
    "het1 = Input((8,1,1))\n",
    "hett1 = Reshape([8],name='he1')(het1)\n",
    "hidden_layers11 = 1\n",
    "for i in range(hidden_layers11):\n",
    "    x11 = Dense(units= 10, activation='tanh', name=\"Dense11{}\".format(i))(hett1)\n",
    "# dropout_rate = 0.2  # you can adjust the dropout rate as needed\n",
    "# dropped1 = Dropout(rate=dropout_rate, name=\"Dropout1\")(x11)\n",
    "dropped1 =  Dense(units=1, activation='tanh',  name=\"Dens1\")(x11)\n",
    "dropped11 = Dense(units=1, activation='tanh', name=\"Dens2\")(dropped1)\n",
    "utilitiesNN = dropped11\n",
    "#utilities ORDINAL\n",
    "main_inputT1= Input((1,1,1), name = 'ugender')\n",
    "utilitiesR1= layer1  (main_inputT1)\n",
    "utilitiesR1= Reshape([1], name='Flatten_Dim1')(utilitiesR1)\n",
    "main_inputT2= Input((1,1,1), name = 'udrv_exp')\n",
    "utilitiesR2= layer2 (main_inputT2)\n",
    "utilitiesR2= Reshape([1], name='Flatten_Dim2')(utilitiesR2)\n",
    "main_inputT3= Input((1,1,1), name = 'uviolation')\n",
    "utilitiesR3= layer3 (main_inputT3)\n",
    "utilitiesR3= Reshape([1], name='Flatten_Dim3')(utilitiesR3)\n",
    "main_inputT4= Input((1,1,1), name = 'uwtp')\n",
    "utilitiesR4= layer4( main_inputT4)\n",
    "utilitiesR4= Reshape([1], name='Flatten_Dim4')(utilitiesR4)\n",
    "main_inputT5= Input((1,1,1), name = 'ubenefit')\n",
    "utilitiesR5= layer5( main_inputT5)\n",
    "utilitiesR5= Reshape([1], name='Flatten_Dim5')(utilitiesR5)\n",
    "main_inputT6= Input((1,1,1), name = 'ubarrier')\n",
    "utilitiesR6= layer6( main_inputT6)\n",
    "utilitiesR6= Reshape([1], name='Flatten_Dim6')(utilitiesR6)\n",
    "main_inputT7= Input((1,1,1), name = 'usafety')\n",
    "utilitiesR7= layer7( main_inputT7)\n",
    "utilitiesR7= Reshape([1], name='Flatten_Dim7')(utilitiesR7)\n",
    "main_inputT8= Input((1,1,1), name = 'uage_34')\n",
    "utilitiesR8= layer8( main_inputT8)\n",
    "utilitiesR8= Reshape([1], name='Flatten_Dim8')(utilitiesR8)\n",
    "# main_inputT9= Input((1,1,1), name = 'uage_44')\n",
    "# utilitiesR9= layer9( main_inputT9)\n",
    "# utilitiesR9= Reshape([1], name='Flatten_Dim9')(utilitiesR9)\n",
    "main_inputT10= Input((1,1,1), name = 'uage_406')\n",
    "utilitiesR10= layer10( main_inputT10)\n",
    "utilitiesR10= Reshape([1], name='Flatten_Dim10')(utilitiesR10)\n",
    "main_inputT11= Input((1,1,1), name = 'uage_60a')\n",
    "utilitiesR11= layer11( main_inputT11)\n",
    "utilitiesR11= Reshape([1], name='Flatten_Dim11')(utilitiesR11)\n",
    "main_inputT12= Input((1,1,1), name = 'ueduc')\n",
    "utilitiesR12= layer12( main_inputT12)\n",
    "utilitiesR12= Reshape([1], name='Flatten_Dim12')(utilitiesR12)\n",
    "main_inputT13= Input((1,1,1), name = 'uincome_5010')\n",
    "utilitiesR13= layer13( main_inputT13)\n",
    "utilitiesR13= Reshape([1], name='Flatten_Dim13')(utilitiesR13)\n",
    "# main_inputT14= Input((1,1,1), name = 'uincome_50')\n",
    "# utilitiesR14= layer14( main_inputT14)\n",
    "# utilitiesR14= Reshape([1], name='Flatten_Dim14')(utilitiesR14)\n",
    "# main_inputT15= Input((1,1,1), name = 'uincome_100')\n",
    "# utilitiesR15= layer15( main_inputT15)\n",
    "# utilitiesR15= Reshape([1], name='Flatten_Dim15')(utilitiesR15)\n",
    "main_inputT16= Input((1,1,1), name = 'uincome_100a')\n",
    "utilitiesR16= layer16( main_inputT16)\n",
    "utilitiesR16= Reshape([1], name='Flatten_Dim16')(utilitiesR16)\n",
    "main_inputT17= Input((1,1,1), name = 'uhousehold')\n",
    "utilitiesR17= layer17( main_inputT17)\n",
    "utilitiesR17= Reshape([1], name='Flatten_Dim17')(utilitiesR17)\n",
    "# main_inputT18= Input((1,1,1), name = 'uoccu')\n",
    "# utilitiesR18= layer18( main_inputT18)\n",
    "# utilitiesR18= Reshape([1], name='Flatten_Dim18')(utilitiesR18)\n",
    "ASC1 =Input((1,1,1), name = 'ASCC')\n",
    "ASC2 =layer19(ASC1)\n",
    "ASC = Reshape([1], name='Flatten_Dim19')(ASC2)\n",
    "final_utilitiesMNL1 = Add(name=\"Utility_functionsMNL1\")([-utilitiesR1,-utilitiesR2,-utilitiesR3,-utilitiesR4,-utilitiesR5,-utilitiesR6,-utilitiesR7,-utilitiesR8,-utilitiesR10,-utilitiesR11,-utilitiesR12,-utilitiesR13,-utilitiesR16,-utilitiesR17,-utilitiesNN, -ASC, tau1])\n",
    "final_utilitiesMNL2 = Add(name=\"Utility_functionsMNL2\")([-utilitiesR1,-utilitiesR2,-utilitiesR3,-utilitiesR4,-utilitiesR5,-utilitiesR6,-utilitiesR7,-utilitiesR8,-utilitiesR10,-utilitiesR11,-utilitiesR12,-utilitiesR13,-utilitiesR16,-utilitiesR17,-utilitiesNN, -ASC, tau2])\n",
    "final_utilitiesMNL3 = Add(name=\"Utility_functionsMNL3\")([-utilitiesR1,-utilitiesR2,-utilitiesR3,-utilitiesR4,-utilitiesR5,-utilitiesR6,-utilitiesR7,-utilitiesR8,-utilitiesR10,-utilitiesR11,-utilitiesR12,-utilitiesR13,-utilitiesR16,-utilitiesR17,-utilitiesNN, -ASC, tau3])\n",
    "final_utilitiesMNL4 = Add(name=\"Utility_functionsMNL4\")([-utilitiesR1,-utilitiesR2,-utilitiesR3,-utilitiesR4,-utilitiesR5,-utilitiesR6,-utilitiesR7,-utilitiesR8,-utilitiesR10,-utilitiesR11,-utilitiesR12,-utilitiesR13,-utilitiesR16,-utilitiesR17,-utilitiesNN, -ASC, tau4])\n",
    "# final_utilitiesMNL5 = Add(name=\"Utility_functionsMNL5\")([utilitiesR1,utilitiesR2,utilitiesR3,utilitiesR4,utilitiesR5,utilitiesNN, -ASC, tau4])\n",
    "probability1 = Dense(units=1, activation='sigmoid',use_bias=False)(final_utilitiesMNL1)\n",
    "probability2 = Dense(units=1, activation='sigmoid',use_bias=False)(final_utilitiesMNL2)\n",
    "probability3 = Dense(units=1, activation='sigmoid',use_bias=False)(final_utilitiesMNL3)\n",
    "probability4 = Dense(units=1, activation='sigmoid',use_bias=False)(final_utilitiesMNL4)\n",
    "problevel1 = probability1\n",
    "problevel2 = probability2 - probability1\n",
    "problevel3 = probability3 - probability2\n",
    "problevel4 = probability4 - probability3\n",
    "problevel5 = 1- probability4\n",
    "#loss\n",
    "#seperatingMNL\n",
    "loss1 = problevel1\n",
    "loss2 = problevel2\n",
    "loss3 = problevel3\n",
    "loss4 = problevel4\n",
    "loss5 = problevel5\n",
    "from keras.layers import Lambda\n",
    "\n",
    "# TotalPro = tf.stack([loss1, loss2, loss3,loss4, loss5], axis=1, name='stackfinal')\n",
    "# TotalPro = Reshape([5]) (TotalPro)\n",
    "\n",
    "TotalPro = Lambda(lambda x: tf.stack(x, axis=1), name='stackfinal')([loss1, loss2, loss3, loss4, loss5])\n",
    "# TotalPro = Dense(5, kernel_regularizer=l2(0.01), use_bias = False)(TotalPro)\n",
    "TotalPro = Reshape([5]) (TotalPro)\n",
    "\n",
    "model = Model(inputs=[main_inputT1,main_inputT2, main_inputT3,main_inputT4,main_inputT5,main_inputT6,main_inputT7,main_inputT8,main_inputT10,main_inputT11,main_inputT12,main_inputT13,main_inputT16,main_inputT17,ASC1,het1,tau11,tau33],outputs=[TotalPro])\n",
    "model.summary()\n",
    "print(model.trainable_variables[0])\n",
    "print(model.trainable_variables[1])\n",
    "print(model.trainable_variables[2])\n",
    "print(model.trainable_variables[3])\n",
    "print(model.trainable_variables[4])\n",
    "print(model.trainable_variables[5])\n",
    "\n",
    "#Regularizer\n",
    "# W11 = model.trainable_variables[0] #weights&parameter\n",
    "# W22 = model.trainable_variables[1]\n",
    "# def custom_loss(weight11,weight22):\n",
    "#     def _custom_loss():\n",
    "#         loss = (10**(-20)) * (tf.sqrt(tf.reduce_sum(tf.square(weight11))+ tf.reduce_sum(tf.square(weight22))))\n",
    "#         return loss\n",
    "#     return _custom_loss\n",
    "# model.add_loss(custom_loss(W11,W22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ec4abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shelve\n",
    "import _pickle as pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD, Adamax\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#from keras.utils import np_utils\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "train_data = np.load(directory_path + 'pav_adopt.npy')\n",
    "train_labels = train_data\n",
    "train_labels = Reshape([5])(train_labels)\n",
    "valid_data = np.load(directory_path + 'choiceV.npy')\n",
    "valid_labels = valid_data\n",
    "valid_labels = Reshape([5])(valid_labels)\n",
    "\n",
    "agender = np.load(directory_path + 'gender.npy')\n",
    "adrv_exp = np.load(directory_path + 'drv_exp.npy')\n",
    "aviolation= np.load(directory_path + 'violation.npy')\n",
    "awtp = np.load(directory_path + 'wtp.npy')\n",
    "abenefit= np.load(directory_path + 'benefit.npy')\n",
    "abarrier= np.load(directory_path + 'barrier.npy')\n",
    "asafety= np.load(directory_path + 'safety.npy')\n",
    "aage_34= np.load(directory_path + 'age_34.npy')\n",
    "# aage_44= np.load(directory_path + 'age_44.npy')\n",
    "aage_406 = np.load(directory_path + 'age_406.npy')\n",
    "aage_60a= np.load(directory_path + 'age_60a.npy')\n",
    "aeduc = np.load(directory_path + 'educ.npy')\n",
    "aincome_5010= np.load(directory_path + 'income_5010.npy')\n",
    "# aincome_50= np.load(directory_path + 'income_50.npy')\n",
    "# aincome_100= np.load(directory_path + 'income_100.npy')\n",
    "aincome_100a= np.load(directory_path + 'income_100a.npy')\n",
    "ahousehold = np.load(directory_path + 'household.npy')\n",
    "# aoccu= np.load(directory_path + 'occu.npy')\n",
    "\n",
    "\n",
    "AASC1=np.load(directory_path + 'ASC.npy')\n",
    "hhet1 = np.load(directory_path + 'NN.npy')\n",
    "ttau = np.load(directory_path + 'tauu.npy')\n",
    "hhet1 = np.delete(hhet1, -1, axis = 2)\n",
    "\n",
    "agenderV = np.load(directory_path + 'genderV.npy')\n",
    "adrv_expV = np.load(directory_path + 'drv_expV.npy')\n",
    "aviolationV= np.load(directory_path + 'violationV.npy')\n",
    "awtpV = np.load(directory_path + 'wtpV.npy')\n",
    "abenefitV= np.load(directory_path + 'benefitV.npy')\n",
    "abarrierV= np.load(directory_path + 'barrierV.npy')\n",
    "asafetyV= np.load(directory_path + 'safetyV.npy')\n",
    "aage_34V= np.load(directory_path + 'age_34V.npy')\n",
    "# aage_44V= np.load(directory_path + 'age_44V.npy')\n",
    "aage_406V = np.load(directory_path + 'age_406V.npy')\n",
    "aage_60aV= np.load(directory_path + 'age_60aV.npy')\n",
    "aeducV = np.load(directory_path + 'educV.npy')\n",
    "aincome_5010V= np.load(directory_path + 'income_5010V.npy')\n",
    "# aincome_50V= np.load(directory_path + 'income_50V.npy')\n",
    "\n",
    "aincome_100aV= np.load(directory_path + 'income_100aV.npy')\n",
    "ahouseholdV= np.load(directory_path + 'householdV.npy')\n",
    "# aoccuV= np.load(directory_path + 'occuV.npy')\n",
    "\n",
    "AASC1V=np.load(directory_path + 'ASCV.npy')\n",
    "hhet1V = np.load(directory_path + 'NNV.npy')\n",
    "ttauV = np.load(directory_path + 'tauuV.npy')\n",
    "hhet1V = np.delete(hhet1V, -1, axis = 2)\n",
    "\n",
    "# print(agender.shape)\n",
    "# print(adrv_exp.shape)\n",
    "# print(aviolation.shape)\n",
    "# print(abenefitfav.shape)\n",
    "# print(abarrierfav.shape)\n",
    "# print(asocialfav.shape)\n",
    "# print(aage_34.shape)\n",
    "# print(aage_44.shape)\n",
    "# print(aage_60.shape)\n",
    "# print(aage_60a.shape)\n",
    "# print(aeduc.shape)\n",
    "# print(aincome_25.shape)\n",
    "# print(aincome_50.shape)\n",
    "# print(aincome_100.shape)\n",
    "# print(aincome_100a.shape)\n",
    "# print(aoccu_pvb.shape)\n",
    "# print(aoccu.shape)\n",
    "# print(AASC1.shape)\n",
    "# print(ttau.shape)\n",
    "\n",
    "# hhet1 = np.reshape(hhet1, (-1, 9, 1, 1))\n",
    "print(\"Shape of hhet1:\", hhet1.shape)\n",
    "train_labels_one_hot = tf.keras.utils.to_categorical(train_labels, num_classes=5)\n",
    "val_labels_one_hot = tf.keras.utils.to_categorical(valid_labels, num_classes=5)\n",
    "# import random\n",
    "# import os\n",
    "\n",
    "# def set_seed(seed=42):\n",
    "#     np.random.seed(seed)\n",
    "#     tf.random.set_seed(seed)\n",
    "#     random.seed(seed)\n",
    "#     os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "#     os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "# set_seed()\n",
    "\n",
    "\n",
    "model.compile(optimizer = Adamax(learning_rate=0.01), loss = ['categorical_crossentropy'], metrics = [tf.keras.metrics.CategoricalAccuracy()])\n",
    "history = model.fit(\n",
    "    [agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau],\n",
    "    [train_labels],\n",
    "    validation_data=([agenderV, adrv_expV, aviolationV, awtpV, abenefitV, abarrierV, asafetyV, aage_34V, aage_406V,aage_60aV, aeducV, aincome_5010V, aincome_100aV, ahouseholdV, AASC1V, hhet1V,ttauV,ttauV], [valid_labels]),\n",
    "    epochs=600,\n",
    "    batch_size=40,\n",
    "    verbose=2,\n",
    "    callbacks=[model_checkpoint]\n",
    ")\n",
    "betas_layer1 = model.get_layer(name = 'gendera')\n",
    "betas_layer2 = model.get_layer(name = 'drv_expa')\n",
    "betas_layer3 = model.get_layer(name = 'violationa')\n",
    "betas_layer4 = model.get_layer(name = 'wtpa')\n",
    "betas_layer5 = model.get_layer(name = 'benefita')\n",
    "betas_layer6 = model.get_layer(name = 'barriera')\n",
    "betas_layer7 = model.get_layer(name = 'safetya')\n",
    "betas_layer8 = model.get_layer(name = 'age_34a')\n",
    "# betas_layer9 = model.get_layer(name = 'age_44a')\n",
    "betas_layer10 = model.get_layer(name = 'age_406aa')\n",
    "betas_layer11 = model.get_layer(name = 'age_60aaa')\n",
    "betas_layer12 = model.get_layer(name = 'educa')\n",
    "betas_layer13 = model.get_layer(name = 'income_5010a')\n",
    "# betas_layer14 = model.get_layer(name = 'income_50a')\n",
    "# betas_layer15 = model.get_layer(name = 'income_100aa')\n",
    "betas_layer16 = model.get_layer(name = 'income_100aaa')\n",
    "betas_layer17 = model.get_layer(name = 'householda')\n",
    "# betas_layer18 = model.get_layer(name = 'occua')\n",
    "betas_layer19 = model.get_layer(name = 'ASCa1')\n",
    "betas_layer20 = model.get_layer(name = 'ttau1a')\n",
    "betas_layer21 = model.get_layer(name = 'ttau3a')\n",
    "# betas_layer22 = model.get_layer(name = 'ttau3a')\n",
    "# betas_layer23 = model.get_layer(name = 'ttau4a')\n",
    "\n",
    "betas1 = betas_layer1.get_weights()\n",
    "betas2 = betas_layer2.get_weights()\n",
    "betas3 = betas_layer3.get_weights()\n",
    "betas4 = betas_layer4.get_weights()\n",
    "betas5 = betas_layer5.get_weights()\n",
    "betas6 = betas_layer6.get_weights()\n",
    "betas7 = betas_layer7.get_weights()\n",
    "betas8 = betas_layer8.get_weights()\n",
    "# betas9 = betas_layer9.get_weights()\n",
    "betas10 = betas_layer10.get_weights()\n",
    "betas11 = betas_layer11.get_weights()\n",
    "betas12 = betas_layer12.get_weights()\n",
    "betas13 = betas_layer13.get_weights()\n",
    "# betas14 = betas_layer14.get_weights()\n",
    "# betas15 = betas_layer15.get_weights()\n",
    "betas16 = betas_layer16.get_weights()\n",
    "betas17 = betas_layer17.get_weights()\n",
    "# betas18 = betas_layer18.get_weights()\n",
    "betas19 = betas_layer19.get_weights()\n",
    "betas20 = betas_layer20.get_weights()\n",
    "betas21 = betas_layer21.get_weights()\n",
    "# betas22 = betas_layer22.get_weights()\n",
    "# betas23 = betas_layer23.get_weights()\n",
    "\n",
    "print (betas1)\n",
    "print (betas2)\n",
    "print (betas3)\n",
    "print (betas4)\n",
    "print (betas5)\n",
    "print (betas6)\n",
    "print (betas7)\n",
    "print (betas8)\n",
    "# print (betas9)\n",
    "print (betas10)\n",
    "print (betas11)\n",
    "print (betas12)\n",
    "print (betas13)\n",
    "# print (betas14)\n",
    "# print (betas15)\n",
    "print (betas16)\n",
    "print (betas17)\n",
    "# # print (betas18)\n",
    "print (betas19)\n",
    "print (betas20)\n",
    "print (betas21)\n",
    "# print (betas22)\n",
    "# print (betas23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1f38bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final loss value from training history\n",
    "final_loss = history.history['loss'][-1]\n",
    "N=597 #number of data points\n",
    "# Calculate log-likelihood\n",
    "log_likelihood = -N * final_loss\n",
    "print(\"Log-Likelihood: \", log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shelve\n",
    "import _pickle as pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#from keras.utils import np_utils\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "model_inputs = [agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau]\n",
    "data_size = len(model_inputs[0])\n",
    "betas_layer1 = model.get_layer(name = 'gendera')\n",
    "betas_layer2 = model.get_layer(name = 'drv_expa')\n",
    "betas_layer3 = model.get_layer(name = 'violationa')\n",
    "betas_layer4 = model.get_layer(name = 'wtpa')\n",
    "betas_layer5 = model.get_layer(name = 'benefita')\n",
    "betas_layer6 = model.get_layer(name = 'barriera')\n",
    "betas_layer7 = model.get_layer(name = 'safetya')\n",
    "betas_layer8 = model.get_layer(name = 'age_34a')\n",
    "# betas_layer9 = model.get_layer(name = 'age_44a')\n",
    "betas_layer10 = model.get_layer(name = 'age_406aa')\n",
    "betas_layer11 = model.get_layer(name = 'age_60aaa')\n",
    "betas_layer12 = model.get_layer(name = 'educa')\n",
    "betas_layer13 = model.get_layer(name = 'income_5010a')\n",
    "# betas_layer14 = model.get_layer(name = 'income_50a')\n",
    "# betas_layer15 = model.get_layer(name = 'income_100aa')\n",
    "betas_layer16 = model.get_layer(name = 'income_100aaa')\n",
    "betas_layer17 = model.get_layer(name = 'householda')\n",
    "# betas_layer18 = model.get_layer(name = 'occua')\n",
    "betas_layer19 = model.get_layer(name = 'ASCa1')\n",
    "betas_layer20 = model.get_layer(name = 'ttau1a')\n",
    "betas_layer21 = model.get_layer(name = 'ttau3a')\n",
    "label=train_labels\n",
    "# label = train_labels_one_hot\n",
    "with tf.GradientTape() as g:\n",
    "    with tf.GradientTape() as g1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "#             print(f\"Shape of labels: {labels.shape}\")\n",
    "#             print(f\"Shape of pred before squeeze: {pred.shape}\")\n",
    "# #             pred = tf.squeeze(pred, axis=-1)\n",
    "#             print(f\"Shape of pred after squeeze: {pred.shape}\")\n",
    "\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1 = g1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op1 = g.jacobian(beta_gradient1, betas_layer1.weights[0])\n",
    "with tf.GradientTape() as h:\n",
    "    with tf.GradientTape() as h1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2 = h1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op2 = h.jacobian(beta_gradient2, betas_layer2.weights[0])\n",
    "\n",
    "with tf.GradientTape() as i:\n",
    "    with tf.GradientTape() as i1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient3 = i1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op3 = i.jacobian(beta_gradient3, betas_layer3.weights[0])\n",
    "\n",
    "with tf.GradientTape() as j:\n",
    "    with tf.GradientTape() as j1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient4 = j1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op4 = j.jacobian(beta_gradient4, betas_layer4.weights[0])\n",
    "\n",
    "with tf.GradientTape() as k:\n",
    "    with tf.GradientTape() as k1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)       \n",
    "    beta_gradient5 = k1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op5 = k.jacobian(beta_gradient5, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as l:\n",
    "    with tf.GradientTape() as l1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)     \n",
    "    beta_gradient6 = l1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op6 = l.jacobian(beta_gradient6, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as n:\n",
    "    with tf.GradientTape() as n1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient7 = n1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op7 = n.jacobian(beta_gradient7, betas_layer7.weights[0])\n",
    "\n",
    "with tf.GradientTape() as m:\n",
    "    with tf.GradientTape() as m1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient8 = m1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op8 = m.jacobian(beta_gradient8, betas_layer8.weights[0])\n",
    "\n",
    "with tf.GradientTape() as o:\n",
    "    with tf.GradientTape() as o1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradienta10 = o1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_opa10 = o.jacobian(beta_gradienta10, betas_layer10.weights[0])\n",
    "\n",
    "with tf.GradientTape() as q:\n",
    "    with tf.GradientTape() as q1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)            \n",
    "    beta_gradienta11 = q1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_opa11 = q.jacobian(beta_gradienta11, betas_layer11.weights[0])\n",
    "\n",
    "with tf.GradientTape() as p:\n",
    "    with tf.GradientTape() as p1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)    \n",
    "    beta_gradienta12 = p1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_opa12 = p.jacobian(beta_gradienta12, betas_layer12.weights[0])\n",
    "\n",
    "with tf.GradientTape() as s:\n",
    "    with tf.GradientTape() as s1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)       \n",
    "    beta_gradienta13 = s1.gradient(loss, betas_layer13.weights[0])[0]\n",
    "Hessian_lines_opa13 = s.jacobian(beta_gradienta13, betas_layer13.weights[0])\n",
    "\n",
    "with tf.GradientTape() as u:\n",
    "    with tf.GradientTape() as u1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)      \n",
    "    beta_gradienta16 = u1.gradient(loss, betas_layer16.weights[0])[0]\n",
    "Hessian_lines_opa16 = u.jacobian(beta_gradienta16, betas_layer16.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ukq:\n",
    "    with tf.GradientTape() as ukq1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)      \n",
    "    beta_gradienta16q = ukq1.gradient(loss, betas_layer17.weights[0])[0]\n",
    "Hessian_lines_opa17 = ukq.jacobian(beta_gradienta16q, betas_layer17.weights[0])\n",
    "\n",
    "with tf.GradientTape() as w:\n",
    "    with tf.GradientTape() as w1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)        \n",
    "    beta_gradienta19 = w1.gradient(loss, betas_layer19.weights[0])[0]\n",
    "Hessian_lines_opa19 = w.jacobian(beta_gradienta19, betas_layer19.weights[0])\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    with tf.GradientTape() as t1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient6a = t1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op12= t.jacobian(beta_gradient6a, betas_layer2.weights[0])\n",
    "\n",
    "with tf.GradientTape() as v:\n",
    "    with tf.GradientTape() as v1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient7a = v1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op13= v.jacobian(beta_gradient7a, betas_layer3.weights[0])\n",
    "\n",
    "with tf.GradientTape() as x:\n",
    "    with tf.GradientTape() as x1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient8a = x1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op23= x.jacobian(beta_gradient8a, betas_layer3.weights[0])\n",
    "\n",
    "with tf.GradientTape() as z:\n",
    "    with tf.GradientTape() as z1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient9a = z1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op14= z.jacobian(beta_gradient9a, betas_layer4.weights[0])\n",
    "\n",
    "with tf.GradientTape() as qa:\n",
    "    with tf.GradientTape() as qa1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient10b = qa1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op24= qa.jacobian(beta_gradient10b, betas_layer4.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ra:\n",
    "    with tf.GradientTape() as ra1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient11b = ra1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op34= ra.jacobian(beta_gradient11b, betas_layer4.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sa:\n",
    "    with tf.GradientTape() as sa1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient12b = sa1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op15= sa.jacobian(beta_gradient12b, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ta:\n",
    "    with tf.GradientTape() as ta1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient13b = ta1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op25= ta.jacobian(beta_gradient13b, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ua:\n",
    "    with tf.GradientTape() as ua1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient14b = ua1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op35= ua.jacobian(beta_gradient14b, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sb:\n",
    "    with tf.GradientTape() as sb1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15b = sb1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op45= sb.jacobian(beta_gradient15b, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sc:\n",
    "    with tf.GradientTape() as sc1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient16b = sc1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op16= sc.jacobian(beta_gradient16b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sd:\n",
    "    with tf.GradientTape() as sd1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient17b = sd1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op26= sd.jacobian(beta_gradient17b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as se:\n",
    "    with tf.GradientTape() as se1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient18b = se1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op36= se.jacobian(beta_gradient18b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sf:\n",
    "    with tf.GradientTape() as sf1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient19b = sf1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op46= sf.jacobian(beta_gradient19b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sg:\n",
    "    with tf.GradientTape() as sg1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient20b = sg1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op56= sg.jacobian(beta_gradient20b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sh:\n",
    "    with tf.GradientTape() as sh1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15c = sh1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op17= sh.jacobian(beta_gradient15c, betas_layer7.weights[0])\n",
    "with tf.GradientTape() as si:\n",
    "    with tf.GradientTape() as si1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient16c = si1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op27= si.jacobian(beta_gradient16c, betas_layer7.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sj:\n",
    "    with tf.GradientTape() as sj1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15ba = sj1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op37= sj.jacobian(beta_gradient15ba, betas_layer7.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sk:\n",
    "    with tf.GradientTape() as sk1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15bc = sk1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op47= sk.jacobian(beta_gradient15bc, betas_layer7.weights[0])\n",
    "with tf.GradientTape() as sl:\n",
    "    with tf.GradientTape() as sl1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15bv = sl1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op57= sl.jacobian(beta_gradient15bv, betas_layer7.weights[0])\n",
    "with tf.GradientTape() as sm:\n",
    "    with tf.GradientTape() as sm1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15bq = sm1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op67= sm.jacobian(beta_gradient15bq, betas_layer7.weights[0])\n",
    "with tf.GradientTape() as sn:\n",
    "    with tf.GradientTape() as sn1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15ca = sn1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op18= sn.jacobian(beta_gradient15ca, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as so:\n",
    "    with tf.GradientTape() as so1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient12b = so1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op28= so.jacobian(beta_gradient12b, betas_layer8.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sp:\n",
    "    with tf.GradientTape() as sp1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient115b = sp1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op38= sp.jacobian(beta_gradient115b, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as sq:\n",
    "    with tf.GradientTape() as sq1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient151b = sq1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op48= sq.jacobian(beta_gradient151b, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as sr:\n",
    "    with tf.GradientTape() as sr1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient11bk = sr1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op58= sr.jacobian(beta_gradient11bk, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as ss:\n",
    "    with tf.GradientTape() as ss1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient11cb = ss1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op68= ss.jacobian(beta_gradient11cb, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as st:\n",
    "    with tf.GradientTape() as st1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient111cb = st1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op78= st.jacobian(beta_gradient111cb, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as su:\n",
    "    with tf.GradientTape() as su1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient112cb = su1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op110= su.jacobian(beta_gradient112cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sv:\n",
    "    with tf.GradientTape() as sv1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient113cb = sv1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op210= sv.jacobian(beta_gradient113cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sw:\n",
    "    with tf.GradientTape() as sw1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient114cb = sw1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op310= sw.jacobian(beta_gradient114cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sx:\n",
    "    with tf.GradientTape() as sx1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient115cb = sx1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op410= sx.jacobian(beta_gradient115cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sy:\n",
    "    with tf.GradientTape() as sy1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient116cb = sy1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op510= sy.jacobian(beta_gradient116cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sz:\n",
    "    with tf.GradientTape() as sz1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient117cb = sz1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op610= sz.jacobian(beta_gradient117cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as s1:\n",
    "    with tf.GradientTape() as s11:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "            \n",
    "    beta_gradient118cb = s11.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op710= s1.jacobian(beta_gradient118cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as s2:\n",
    "    with tf.GradientTape() as s21:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "            \n",
    "    beta_gradient119cb = s21.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op810= s2.jacobian(beta_gradient119cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as s3:\n",
    "    with tf.GradientTape() as s13:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient211cb = s13.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op111= s3.jacobian(beta_gradient211cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s4:\n",
    "    with tf.GradientTape() as s14:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient311cb = s14.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op211= s4.jacobian(beta_gradient311cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s5:\n",
    "    with tf.GradientTape() as s15:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient411cb = s15.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op311= s5.jacobian(beta_gradient411cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s6:\n",
    "    with tf.GradientTape() as s16:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient511cb = s16.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op411= s6.jacobian(beta_gradient511cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s7:\n",
    "    with tf.GradientTape() as s17:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient611cb = s17.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op511= s7.jacobian(beta_gradient611cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s8:\n",
    "    with tf.GradientTape() as s18:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient711cb = s18.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op611= s8.jacobian(beta_gradient711cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s9:\n",
    "    with tf.GradientTape() as s19:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient811cb = s19.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op711= s9.jacobian(beta_gradient811cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as a1:\n",
    "    with tf.GradientTape() as a111:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient911cb = a111.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op811= a1.jacobian(beta_gradient911cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as b:\n",
    "    with tf.GradientTape() as bb1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1011cb = bb1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1011= b.jacobian(beta_gradient1011cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as cc:\n",
    "    with tf.GradientTape() as cc1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1111cb = cc1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op112= cc.jacobian(beta_gradient1111cb, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as dd:\n",
    "    with tf.GradientTape() as dd1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1211cb = dd1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op212= dd.jacobian(beta_gradient1211cb, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as ee:\n",
    "    with tf.GradientTape() as ee1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1311cb = ee1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op312= ee.jacobian(beta_gradient1311cb, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as ff:\n",
    "    with tf.GradientTape() as ff1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1lp = ff1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op412= ff.jacobian(beta_gradient1lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as gg:\n",
    "    with tf.GradientTape() as gg1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2lp = gg1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op512= gg.jacobian(beta_gradient2lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as hh:\n",
    "    with tf.GradientTape() as hh1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient3lp = hh1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op612= hh.jacobian(beta_gradient3lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as ii:\n",
    "    with tf.GradientTape() as ii1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient4lp = ii1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op712= ii.jacobian(beta_gradient4lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as sjj:\n",
    "    with tf.GradientTape() as sjj1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient5lp = sjj1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op812= sjj.jacobian(beta_gradient5lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as skk:\n",
    "    with tf.GradientTape() as skk1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient6lp = skk1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1012= skk.jacobian(beta_gradient6lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as sll:\n",
    "    with tf.GradientTape() as sll1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient7lp = sll1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1112= sll.jacobian(beta_gradient7lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as smm:\n",
    "    with tf.GradientTape() as smm1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient8lp = smm1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op113= smm.jacobian(beta_gradient8lp, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as snn:\n",
    "    with tf.GradientTape() as snn1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient9lp = snn1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op213= snn.jacobian(beta_gradient9lp, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as spp:\n",
    "    with tf.GradientTape() as spp1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient10lp = spp1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op313= spp.jacobian(beta_gradient10lp, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as sqq:\n",
    "    with tf.GradientTape() as sqq1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient11lp = sqq1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op413= sqq.jacobian(beta_gradient11lp, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as srr:\n",
    "    with tf.GradientTape() as srr1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient12lq = srr1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op513= srr.jacobian(beta_gradient12lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as stt:\n",
    "    with tf.GradientTape() as stt1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient13lq = stt1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op613= stt.jacobian(beta_gradient13lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as suu:\n",
    "    with tf.GradientTape() as suu1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient14lq = suu1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op713= suu.jacobian(beta_gradient14lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as suu2:\n",
    "    with tf.GradientTape() as suu3:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15lq = suu3.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op813= suu2.jacobian(beta_gradient15lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as svv:\n",
    "    with tf.GradientTape() as svv1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient16lq = svv1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1013= svv.jacobian(beta_gradient16lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as stt:\n",
    "    with tf.GradientTape() as stt1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient17lq = stt1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1113= stt.jacobian(beta_gradient17lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as sxx:\n",
    "    with tf.GradientTape() as sxx1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient18lq = sxx1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_op1213= sxx.jacobian(beta_gradient18lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as syy:\n",
    "    with tf.GradientTape() as syy1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient19lq = syy1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op116= syy.jacobian(beta_gradient19lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as szz:\n",
    "    with tf.GradientTape() as szz1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient20lq = szz1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op216= szz.jacobian(beta_gradient20lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as zzs:\n",
    "    with tf.GradientTape() as zzs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient21lq = zzs1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op316= zzs.jacobian(beta_gradient21lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as yys:\n",
    "    with tf.GradientTape() as yys1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient212lq = yys1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op416= yys.jacobian(beta_gradient212lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as xxs:\n",
    "    with tf.GradientTape() as xxs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient213lq = xxs1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op516= xxs.jacobian(beta_gradient213lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as uus:\n",
    "    with tf.GradientTape() as uus1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient214lq = uus1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op616= uus.jacobian(beta_gradient214lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as vvs:\n",
    "    with tf.GradientTape() as vvs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient215lq = vvs1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op716= vvs.jacobian(beta_gradient215lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as ccs:\n",
    "    with tf.GradientTape() as ccs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient216lq = ccs1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op816= ccs.jacobian(beta_gradient216lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as dds:\n",
    "    with tf.GradientTape() as dds1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient271lq = dds1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1016= dds.jacobian(beta_gradient271lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as ees:\n",
    "    with tf.GradientTape() as ees1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient218lq = ees1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1116= ees.jacobian(beta_gradient218lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as ffs:\n",
    "    with tf.GradientTape() as ffs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient219lq = ffs1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_op1216= ffs.jacobian(beta_gradient219lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as ggs:\n",
    "    with tf.GradientTape() as ggs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2120lq = ggs1.gradient(loss, betas_layer13.weights[0])[0]\n",
    "Hessian_lines_op1316= ggs.jacobian(beta_gradient2120lq, betas_layer16.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ggsp:\n",
    "    with tf.GradientTape() as ggsp1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2120lqg = ggsp1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op117= ggsp.jacobian(beta_gradient2120lqg, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as ggs11:\n",
    "    with tf.GradientTape() as ggs111:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2120lq1 = ggs111.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op217= ggs11.jacobian(beta_gradient2120lq1, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnl:\n",
    "    with tf.GradientTape() as nnl1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient7190lqn = nnl1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op317= nnl.jacobian(beta_gradient7190lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnla:\n",
    "    with tf.GradientTape() as nnla1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71901lqn = nnla1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op417= nnla.jacobian(beta_gradient71901lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlb:\n",
    "    with tf.GradientTape() as nnlb1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71902lqn = nnlb1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op517= nnlb.jacobian(beta_gradient71902lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlc:\n",
    "    with tf.GradientTape() as nnlc1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71903lqn = nnlc1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op617= nnlc.jacobian(beta_gradient71903lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnld:\n",
    "    with tf.GradientTape() as nnld1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71904lqn = nnld1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op717= nnld.jacobian(beta_gradient71904lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnle:\n",
    "    with tf.GradientTape() as nnle1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71905lqn = nnle1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op817= nnle.jacobian(beta_gradient71905lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlf:\n",
    "    with tf.GradientTape() as nnlf1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71906lqn = nnlf1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1017= nnlf.jacobian(beta_gradient71906lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlg:\n",
    "    with tf.GradientTape() as nnlg1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71907lqn = nnlg1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1117= nnlg.jacobian(beta_gradient71907lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlh:\n",
    "    with tf.GradientTape() as nnlh1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71908lqn = nnlh1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_op1217= nnlh.jacobian(beta_gradient71908lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnli:\n",
    "    with tf.GradientTape() as nnli1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71909lqn = nnli1.gradient(loss, betas_layer13.weights[0])[0]\n",
    "Hessian_lines_op1317= nnli.jacobian(beta_gradient71909lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlha:\n",
    "    with tf.GradientTape() as nnlha1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient719011lqn = nnlha1.gradient(loss, betas_layer16.weights[0])[0]\n",
    "Hessian_lines_op1617= nnlha.jacobian(beta_gradient719011lqn, betas_layer17.weights[0])\n",
    "\n",
    "with tf.GradientTape() as hhs:\n",
    "    with tf.GradientTape() as hhs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2121lq = hhs1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op119= hhs.jacobian(beta_gradient2121lq, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as jjs:\n",
    "    with tf.GradientTape() as jjs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient21vu = jjs1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op219= jjs.jacobian(beta_gradient21vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as kks:\n",
    "    with tf.GradientTape() as kks1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient212vu = kks1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op319= kks.jacobian(beta_gradient212vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as mms:\n",
    "    with tf.GradientTape() as mms1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient213vu = mms1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op419= mms.jacobian(beta_gradient213vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as nns:\n",
    "    with tf.GradientTape() as nns1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient214vu = nns1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op519= nns.jacobian(beta_gradient214vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as pps:\n",
    "    with tf.GradientTape() as pps1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient215vu = pps1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op619= pps.jacobian(beta_gradient215vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as rrs:\n",
    "    with tf.GradientTape() as rrs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient216vu = rrs1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op719= rrs.jacobian(beta_gradient216vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as uus:\n",
    "    with tf.GradientTape() as uus1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient217vu = uus1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op819= uus.jacobian(beta_gradient217vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as aaas:\n",
    "    with tf.GradientTape() as aaas1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient218vu = aaas1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1019= aaas.jacobian(beta_gradient218vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as bbbs:\n",
    "    with tf.GradientTape() as bbbs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient219vu = bbbs1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1119= bbbs.jacobian(beta_gradient219vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as cccs:\n",
    "    with tf.GradientTape() as cccs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2120vu = cccs1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_op1219= cccs.jacobian(beta_gradient2120vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as ddds:\n",
    "    with tf.GradientTape() as ddds1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2121vu = ddds1.gradient(loss, betas_layer13.weights[0])[0]\n",
    "Hessian_lines_op1319= ddds.jacobian(beta_gradient2121vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as fffs:\n",
    "    with tf.GradientTape() as fffs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2122vu = fffs1.gradient(loss, betas_layer16.weights[0])[0]\n",
    "Hessian_lines_op1619= fffs.jacobian(beta_gradient2122vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as gggs:\n",
    "    with tf.GradientTape() as gggs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2123vu = gggs1.gradient(loss, betas_layer17.weights[0])[0]\n",
    "Hessian_lines_op1719= gggs.jacobian(beta_gradient2123vu, betas_layer19.weights[0])\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hessian1= ([[Hessian_lines_op1, Hessian_lines_op12, Hessian_lines_op13,Hessian_lines_op14,Hessian_lines_op15,Hessian_lines_op16,Hessian_lines_op17,Hessian_lines_op18,Hessian_lines_op110,Hessian_lines_op111,Hessian_lines_op112,Hessian_lines_op113,Hessian_lines_op116,Hessian_lines_op117,Hessian_lines_op119], \n",
    "            [Hessian_lines_op12, Hessian_lines_op2,Hessian_lines_op23,Hessian_lines_op24,Hessian_lines_op25,Hessian_lines_op26,Hessian_lines_op27,Hessian_lines_op28,Hessian_lines_op210,Hessian_lines_op211,Hessian_lines_op212,Hessian_lines_op213,Hessian_lines_op216,Hessian_lines_op217,Hessian_lines_op219],\n",
    "            [Hessian_lines_op13, Hessian_lines_op23,Hessian_lines_op3, Hessian_lines_op34, Hessian_lines_op35, Hessian_lines_op36, Hessian_lines_op37, Hessian_lines_op38, Hessian_lines_op310, Hessian_lines_op311, Hessian_lines_op312, Hessian_lines_op313, Hessian_lines_op316,Hessian_lines_op317, Hessian_lines_op319], \n",
    "            [Hessian_lines_op14, Hessian_lines_op24,Hessian_lines_op34, Hessian_lines_op4, Hessian_lines_op45, Hessian_lines_op46, Hessian_lines_op47, Hessian_lines_op48, Hessian_lines_op410, Hessian_lines_op411, Hessian_lines_op412, Hessian_lines_op413, Hessian_lines_op416,Hessian_lines_op417, Hessian_lines_op419],\n",
    "            [Hessian_lines_op15, Hessian_lines_op25,Hessian_lines_op35, Hessian_lines_op45, Hessian_lines_op5, Hessian_lines_op56, Hessian_lines_op57, Hessian_lines_op58, Hessian_lines_op510, Hessian_lines_op511, Hessian_lines_op512, Hessian_lines_op513, Hessian_lines_op516, Hessian_lines_op517,Hessian_lines_op519],\n",
    "           [Hessian_lines_op16, Hessian_lines_op26,Hessian_lines_op36, Hessian_lines_op46, Hessian_lines_op56, Hessian_lines_op6, Hessian_lines_op67, Hessian_lines_op68, Hessian_lines_op610, Hessian_lines_op611, Hessian_lines_op612, Hessian_lines_op613, Hessian_lines_op616, Hessian_lines_op617,Hessian_lines_op619],\n",
    "           [Hessian_lines_op17, Hessian_lines_op27,Hessian_lines_op37, Hessian_lines_op47, Hessian_lines_op57, Hessian_lines_op67, Hessian_lines_op7, Hessian_lines_op78, Hessian_lines_op710, Hessian_lines_op711, Hessian_lines_op712, Hessian_lines_op713, Hessian_lines_op716, Hessian_lines_op717,Hessian_lines_op719],\n",
    "           [Hessian_lines_op18, Hessian_lines_op28,Hessian_lines_op38, Hessian_lines_op48, Hessian_lines_op58, Hessian_lines_op68, Hessian_lines_op78, Hessian_lines_op8, Hessian_lines_op810, Hessian_lines_op811, Hessian_lines_op812, Hessian_lines_op813, Hessian_lines_op816, Hessian_lines_op817,Hessian_lines_op819],\n",
    "           [Hessian_lines_op110, Hessian_lines_op210,Hessian_lines_op310, Hessian_lines_op410, Hessian_lines_op510, Hessian_lines_op610, Hessian_lines_op710, Hessian_lines_op810, Hessian_lines_opa10, Hessian_lines_op1011, Hessian_lines_op1012, Hessian_lines_op1013, Hessian_lines_op1016,Hessian_lines_op1017, Hessian_lines_op1019],\n",
    "           [Hessian_lines_op111, Hessian_lines_op211,Hessian_lines_op311, Hessian_lines_op411, Hessian_lines_op511, Hessian_lines_op611, Hessian_lines_op711, Hessian_lines_op811, Hessian_lines_op1011, Hessian_lines_opa11, Hessian_lines_op1112, Hessian_lines_op1113, Hessian_lines_op1116, Hessian_lines_op1117,Hessian_lines_op1119],\n",
    "           [Hessian_lines_op112, Hessian_lines_op212,Hessian_lines_op312, Hessian_lines_op412, Hessian_lines_op512, Hessian_lines_op612, Hessian_lines_op712, Hessian_lines_op812, Hessian_lines_op1012, Hessian_lines_op1112, Hessian_lines_opa12, Hessian_lines_op1213, Hessian_lines_op1216, Hessian_lines_op1217,Hessian_lines_op1219],\n",
    "           [Hessian_lines_op113, Hessian_lines_op213,Hessian_lines_op313, Hessian_lines_op413, Hessian_lines_op513, Hessian_lines_op613, Hessian_lines_op713, Hessian_lines_op813, Hessian_lines_op1013, Hessian_lines_op1113, Hessian_lines_op1213, Hessian_lines_opa13, Hessian_lines_op1316, Hessian_lines_op1317,Hessian_lines_op1319],\n",
    "           [Hessian_lines_op116, Hessian_lines_op216,Hessian_lines_op316, Hessian_lines_op416, Hessian_lines_op516, Hessian_lines_op616, Hessian_lines_op716, Hessian_lines_op816, Hessian_lines_op1016, Hessian_lines_op1116, Hessian_lines_op1216, Hessian_lines_op1316, Hessian_lines_opa16, Hessian_lines_op1617,Hessian_lines_op1619],\n",
    "            [Hessian_lines_op117, Hessian_lines_op217,Hessian_lines_op317, Hessian_lines_op417, Hessian_lines_op517, Hessian_lines_op617, Hessian_lines_op717, Hessian_lines_op817, Hessian_lines_op1017, Hessian_lines_op1117, Hessian_lines_op1217, Hessian_lines_op1317, Hessian_lines_op1617, Hessian_lines_opa17,Hessian_lines_op1719],\n",
    "           [Hessian_lines_op119, Hessian_lines_op219,Hessian_lines_op319, Hessian_lines_op419, Hessian_lines_op519, Hessian_lines_op619, Hessian_lines_op719, Hessian_lines_op819, Hessian_lines_op1019, Hessian_lines_op1119, Hessian_lines_op1219, Hessian_lines_op1319, Hessian_lines_op1619, Hessian_lines_op1719,Hessian_lines_opa19]])\n",
    "Hessian = np.squeeze(Hessian1)*data_size\n",
    "invHess = np.linalg.inv(Hessian)\n",
    "\n",
    "# Extract the diagonal elements\n",
    "diagonal_elements = np.diag(invHess)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
