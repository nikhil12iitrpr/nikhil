{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e54bbaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in true_class: [1 2 3 4 5]\n",
      "Total Likelihood for Validation Data: 3.979044777580559e-37\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from scipy.special import expit\n",
    "\n",
    "\n",
    "\n",
    "# # Define the beta values as given, excluding delta_u1 and delta_u2\n",
    "# beta_values = {\n",
    "#     'ASC_choice': -0.275,\n",
    "#     'gender': 0.148,\n",
    "#     'drv_exp': 0.391,\n",
    "#     'violations': -0.160,\n",
    "#     'wtp': 0.761,\n",
    "#     'benefit': 0.512,\n",
    "#     'barrier': -0.007,\n",
    "#     'safety': 0.235,\n",
    "#     'age_34': -0.185,\n",
    "#     'age_406': -0.409,\n",
    "#     'age_60a': -0.546,    \n",
    "#     'educ': 0.575,\n",
    "#     'income_5010': 0.832,\n",
    "#     'income_100a': 1.622,\n",
    "#     'household': 0.409,\n",
    "# }\n",
    "\n",
    "# # Example features from validation dataset\n",
    "# features = ['gender', 'drv_exp', 'violations', 'wtp', 'benefit', 'barrier', 'safety', 'age_34', 'age_406', 'age_60a', 'educ', 'income_5010', 'income_100a', 'household']\n",
    "# X_valid = valid_df[features].values\n",
    "\n",
    "# # Calculate the linear combination of inputs and beta values (utility)\n",
    "# def calculate_utility(X, beta_values, features):\n",
    "#     intercept = beta_values['ASC_choice']\n",
    "#     beta = np.array([beta_values[feature] for feature in features])\n",
    "#     utility = np.dot(X, beta) + intercept\n",
    "#     return utility\n",
    "\n",
    "# # Calculate the predicted probabilities for each class (categories)\n",
    "# def calculate_probabilities(utility, thresholds):\n",
    "#     thresholds = [-np.inf] + thresholds + [np.inf]  # Adding extreme thresholds\n",
    "#     probabilities = np.zeros((utility.shape[0], len(thresholds) - 1))  # Probability for each category\n",
    "    \n",
    "#     # Calculate the probabilities for each category (from 0 to 4 for a 5-point scale)\n",
    "#     for i in range(1, len(thresholds)):\n",
    "#         probabilities[:, i - 1] = expit(thresholds[i] - utility) - expit(thresholds[i - 1] - utility)\n",
    "    \n",
    "#     return probabilities\n",
    "\n",
    "# # Thresholds for the ordinal categories (you can adjust them based on your data)\n",
    "# thresholds = [-2.417, -0.766, 0.766, 2.417]  # Example, modify if needed for your scale\n",
    "\n",
    "# # Calculate utility for validation data\n",
    "# utility_valid = calculate_utility(X_valid, beta_values, features)\n",
    "\n",
    "# # Predict probabilities for each category (5 categories in total)\n",
    "# probabilities_valid = calculate_probabilities(utility_valid, thresholds)\n",
    "\n",
    "# # Get true class labels from the 'pav_adopt' column\n",
    "# true_class = valid_df['pav_adopt'].values\n",
    "\n",
    "# # Check if any true_class values are out of bounds\n",
    "# print(\"Unique values in true_class:\", np.unique(true_class))\n",
    "\n",
    "# # Ensure true_class values are within the valid range [0, 4] for the 5-point Likert scale\n",
    "# true_class = np.clip(true_class, 0, 4)\n",
    "\n",
    "# # Calculate the likelihood for each observation\n",
    "# likelihood = np.prod([probabilities_valid[i, true_class[i]] for i in range(len(true_class))])\n",
    "\n",
    "# print(f\"Total Likelihood for Validation Data: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5404e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in true_class: [1 2 3 4 5]\n",
      "Total Likelihood for Validation Data: 3.979044777580559e-37\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from scipy.special import expit\n",
    "# import pandas as pd  # Make sure to import pandas to read the CSV file\n",
    "\n",
    "# # Load the validation dataset\n",
    "# valid_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "\n",
    "# # Define the beta values as given, excluding delta_u1 and delta_u2\n",
    "# beta_values = {\n",
    "#     'ASC_choice': -0.275,\n",
    "#     'gender': 0.148,\n",
    "#     'drv_exp': 0.391,\n",
    "#     'violations': -0.160,\n",
    "#     'wtp': 0.761,\n",
    "#     'benefit': 0.512,\n",
    "#     'barrier': -0.007,\n",
    "#     'safety': 0.235,\n",
    "#     'age_34': -0.185,\n",
    "#     'age_406': -0.409,\n",
    "#     'age_60a': -0.546,    \n",
    "#     'educ': 0.575,\n",
    "#     'income_5010': 0.832,\n",
    "#     'income_100a': 1.622,\n",
    "#     'household': 0.409,\n",
    "# }\n",
    "\n",
    "# # Example features from validation dataset\n",
    "# features = ['gender', 'drv_exp', 'violations', 'wtp', 'benefit', 'barrier', 'safety', 'age_34', 'age_406', 'age_60a', 'educ', 'income_5010', 'income_100a', 'household']\n",
    "\n",
    "# # Make sure the features in the dataset are the same as those in the 'features' list\n",
    "# X_valid = valid_df[features].values\n",
    "\n",
    "# # Calculate the linear combination of inputs and beta values (utility)\n",
    "# def calculate_utility(X, beta_values, features):\n",
    "#     intercept = beta_values['ASC_choice']\n",
    "#     beta = np.array([beta_values[feature] for feature in features])\n",
    "#     utility = np.dot(X, beta) + intercept\n",
    "#     return utility\n",
    "\n",
    "# # Calculate the predicted probabilities for each class (categories)\n",
    "# def calculate_probabilities(utility, thresholds):\n",
    "#     thresholds = [-np.inf] + thresholds + [np.inf]  # Adding extreme thresholds\n",
    "#     probabilities = np.zeros((utility.shape[0], len(thresholds) - 1))  # Probability for each category\n",
    "    \n",
    "#     # Calculate the probabilities for each category (from 0 to 4 for a 5-point scale)\n",
    "#     for i in range(1, len(thresholds)):\n",
    "#         probabilities[:, i - 1] = expit(thresholds[i] - utility) - expit(thresholds[i - 1] - utility)\n",
    "    \n",
    "#     return probabilities\n",
    "\n",
    "# # Thresholds for the ordinal categories (you can adjust them based on your data)\n",
    "# thresholds = [-2.417, -0.766, 0.766, 2.417]  # Example, modify if needed for your scale\n",
    "\n",
    "# # Calculate utility for validation data\n",
    "# utility_valid = calculate_utility(X_valid, beta_values, features)\n",
    "\n",
    "# # Predict probabilities for each category (5 categories in total)\n",
    "# probabilities_valid = calculate_probabilities(utility_valid, thresholds)\n",
    "\n",
    "# # Get true class labels from the 'pav_adopt' column\n",
    "# true_class = valid_df['pav_adopt'].values\n",
    "\n",
    "# # Check if any true_class values are out of bounds\n",
    "# print(\"Unique values in true_class:\", np.unique(true_class))\n",
    "\n",
    "# # Ensure true_class values are within the valid range [0, 4] for the 5-point Likert scale\n",
    "# true_class = np.clip(true_class, 0, 4)\n",
    "\n",
    "# # Calculate the likelihood for each observation\n",
    "# likelihood = np.prod([probabilities_valid[i, true_class[i]] for i in range(len(true_class))])\n",
    "\n",
    "# print(f\"Total Likelihood for Validation Data: {likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bbfce72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Likelihood for Validation Data (multiplied by 66): 2.626169553203169e-35\n"
     ]
    }
   ],
   "source": [
    "# # Multiply the final likelihood by 66\n",
    "# likelihood = likelihood * 66\n",
    "\n",
    "# print(f\"Total Likelihood for Validation Data (multiplied by 66): {likelihood}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9002205c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in true_class: [1 2 3 4 5]\n",
      "Total Log-Likelihood for Validation Data (multiplied by number of data points): -5531.764039290874\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "import pandas as pd  # Make sure to import pandas to read the CSV file\n",
    "\n",
    "# Load the validation dataset\n",
    "valid_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "\n",
    "# Define the beta values as given, excluding delta_u1 and delta_u2\n",
    "beta_values = {\n",
    "    'ASC_choice': -0.275,\n",
    "    'gender': 0.148,\n",
    "    'drv_exp': 0.391,\n",
    "    'violations': -0.160,\n",
    "    'wtp': 0.761,\n",
    "    'benefit': 0.512,\n",
    "    'barrier': -0.007,\n",
    "    'safety': 0.235,\n",
    "    'age_34': -0.185,\n",
    "    'age_406': -0.409,\n",
    "    'age_60a': -0.546,    \n",
    "    'educ': 0.575,\n",
    "    'income_5010': 0.832,\n",
    "    'income_100a': 1.622,\n",
    "    'household': 0.409,\n",
    "}\n",
    "\n",
    "# Example features from validation dataset\n",
    "features = ['gender', 'drv_exp', 'violations', 'wtp', 'benefit', 'barrier', 'safety', 'age_34', 'age_406', 'age_60a', 'educ', 'income_5010', 'income_100a', 'household']\n",
    "\n",
    "# Make sure the features in the dataset are the same as those in the 'features' list\n",
    "X_valid = valid_df[features].values\n",
    "\n",
    "# Calculate the linear combination of inputs and beta values (utility)\n",
    "def calculate_utility(X, beta_values, features):\n",
    "    intercept = beta_values['ASC_choice']\n",
    "    beta = np.array([beta_values[feature] for feature in features])\n",
    "    utility = np.dot(X, beta) + intercept\n",
    "    return utility\n",
    "\n",
    "# Calculate the predicted probabilities for each class (categories)\n",
    "def calculate_probabilities(utility, thresholds):\n",
    "    thresholds = [-np.inf] + thresholds + [np.inf]  # Adding extreme thresholds\n",
    "    probabilities = np.zeros((utility.shape[0], len(thresholds) - 1))  # Probability for each category\n",
    "    \n",
    "    # Calculate the probabilities for each category (from 0 to 4 for a 5-point scale)\n",
    "    for i in range(1, len(thresholds)):\n",
    "        probabilities[:, i - 1] = expit(thresholds[i] - utility) - expit(thresholds[i - 1] - utility)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# Thresholds for the ordinal categories (you can adjust them based on your data)\n",
    "thresholds = [-2.417, -0.766, 0.766, 2.417]  # Example, modify if needed for your scale\n",
    "\n",
    "# Calculate utility for validation data\n",
    "utility_valid = calculate_utility(X_valid, beta_values, features)\n",
    "\n",
    "# Predict probabilities for each category (5 categories in total)\n",
    "probabilities_valid = calculate_probabilities(utility_valid, thresholds)\n",
    "\n",
    "# Get true class labels from the 'pav_adopt' column\n",
    "true_class = valid_df['pav_adopt'].values\n",
    "\n",
    "# Check if any true_class values are out of bounds\n",
    "print(\"Unique values in true_class:\", np.unique(true_class))\n",
    "\n",
    "# Ensure true_class values are within the valid range [0, 4] for the 5-point Likert scale\n",
    "true_class = np.clip(true_class, 0, 4)\n",
    "\n",
    "# Calculate the log-likelihood for each observation\n",
    "log_likelihood = np.sum([np.log(probabilities_valid[i, true_class[i]]) for i in range(len(true_class))])\n",
    "\n",
    "# Optionally, multiply the log-likelihood by the number of data points (if necessary)\n",
    "num_data_points = len(valid_df)\n",
    "log_likelihood *= num_data_points\n",
    "\n",
    "print(f\"Total Log-Likelihood for Validation Data (multiplied by number of data points): {log_likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e7d4b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in true_class: [1 2 3 4 5]\n",
      "Total Log-Likelihood for Validation Data (multiplied by number of data points): -6524.897406119925\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_train_data.csv', delimiter=',')\n",
    "valid_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "\n",
    "# Define the beta values as given, excluding delta_u1 and delta_u2\n",
    "beta_values = {\n",
    "    'ASC_choice': -0.595242,\n",
    "    'age_34': -0.464718,\n",
    "    'age_406': -0.786452,\n",
    "    'age_60a': -0.801910,\n",
    "    'barrier': -0.160703,\n",
    "    'benefit': 0.572527,\n",
    "    'wtp': 0.819343,\n",
    "    'drv_exp': 0.414999,\n",
    "    'educ': 0.787757,\n",
    "    'gender': 0.105606,\n",
    "    'household': 0.385161,\n",
    "    'income_100a': 2.481842,\n",
    "    'income_5010': 1.124828,\n",
    "    'safety': 0.205917,\n",
    "    'violations': -0.419996\n",
    "}\n",
    "\n",
    "# Define thresholds for the ordinal logistic model\n",
    "thresholds = [-2.844465, -0.991237, 0.991237, 2.844465]\n",
    "# Example features from validation dataset\n",
    "features = ['gender', 'drv_exp', 'violations', 'wtp', 'benefit', 'barrier', 'safety', 'age_34', 'age_406', 'age_60a', 'educ', 'income_5010', 'income_100a', 'household']\n",
    "# Make sure the features in the dataset are the same as those in the 'features' list\n",
    "X_valid = valid_df[features].values\n",
    "\n",
    "# Calculate the linear combination of inputs and beta values (utility)\n",
    "def calculate_utility(X, beta_values, features):\n",
    "    intercept = beta_values['ASC_choice']\n",
    "    beta = np.array([beta_values[feature] for feature in features])\n",
    "    utility = np.dot(X, beta) + intercept\n",
    "    return utility\n",
    "\n",
    "# Calculate the predicted probabilities for each class (categories)\n",
    "def calculate_probabilities(utility, thresholds):\n",
    "    thresholds = [-np.inf] + thresholds + [np.inf]  # Adding extreme thresholds\n",
    "    probabilities = np.zeros((utility.shape[0], len(thresholds) - 1))  # Probability for each category\n",
    "    \n",
    "    # Calculate the probabilities for each category (from 0 to 4 for a 5-point scale)\n",
    "    for i in range(1, len(thresholds)):\n",
    "        probabilities[:, i - 1] = expit(thresholds[i] - utility) - expit(thresholds[i - 1] - utility)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# # Thresholds for the ordinal categories (you can adjust them based on your data)\n",
    "# thresholds = [-2.417, -0.766, 0.766, 2.417]  # Example, modify if needed for your scale\n",
    "\n",
    "# Calculate utility for validation data\n",
    "utility_valid = calculate_utility(X_valid, beta_values, features)\n",
    "\n",
    "# Predict probabilities for each category (5 categories in total)\n",
    "probabilities_valid = calculate_probabilities(utility_valid, thresholds)\n",
    "\n",
    "# Get true class labels from the 'pav_adopt' column\n",
    "true_class = valid_df['pav_adopt'].values\n",
    "\n",
    "# Check if any true_class values are out of bounds\n",
    "print(\"Unique values in true_class:\", np.unique(true_class))\n",
    "\n",
    "# Ensure true_class values are within the valid range [0, 4] for the 5-point Likert scale\n",
    "true_class = np.clip(true_class, 0, 4)\n",
    "\n",
    "# Calculate the log-likelihood for each observation\n",
    "log_likelihood = np.sum([np.log(probabilities_valid[i, true_class[i]]) for i in range(len(true_class))])\n",
    "\n",
    "# Optionally, multiply the log-likelihood by the number of data points (if necessary)\n",
    "num_data_points = len(valid_df)\n",
    "log_likelihood *= num_data_points\n",
    "\n",
    "print(f\"Total Log-Likelihood for Validation Data (multiplied by number of data points): {log_likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ff4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.special import expit\n",
    "\n",
    "# # Load the datasets\n",
    "# train_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_train_data.csv', delimiter=',')\n",
    "# valid_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "\n",
    "# # Define the beta values as given, excluding delta_u1 and delta_u2\n",
    "# beta_values = {\n",
    "#     'ASC_choice': -0.301670,\n",
    "#     'age_34': -0.158519,\n",
    "#     'age_406': -0.113005,\n",
    "#     'age_60a': 1.026286,\n",
    "#     'barrierfav': 0.322986,\n",
    "#     'benefitfav': 0.526285,\n",
    "#     'veh_time': 0.426917,\n",
    "#     'drv_exp': 0.370264,\n",
    "#     'educ': 0.932824,\n",
    "#     'gender': -0.405385,\n",
    "#     'income_100a': 1.878591,\n",
    "#     'income_5010': 0.574125,\n",
    "#     'socialfav': 0.166702,\n",
    "#     'violations': -0.459699\n",
    "# }\n",
    "\n",
    "# # Define thresholds for the ordinal logistic model\n",
    "# thresholds = [-2.939, -0.782, 0.782, 2.939]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "217c2368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in true_class: [1 2 3 4 5]\n",
      "Total Log-Likelihood for Validation Data (multiplied by number of data points): -6467.266053379412\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, mean_squared_error\n",
    "from scipy.special import expit  # Sigmoid function\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_train_data.csv', delimiter=',')\n",
    "valid_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "\n",
    "# Define the beta values as given, excluding delta_u1 and delta_u2\n",
    "beta_values = {\n",
    "    'ASC_choice': -0.153,\n",
    "    'gender': -0.224,\n",
    "    'drv_exp': 0.243,\n",
    "    'violations': -0.287,\n",
    "    'veh_time': 0.229,\n",
    "    'benefitfav': 0.141,\n",
    "    'barrierfav': 0.074,\n",
    "    'socialfav': -0.075,\n",
    "    'age_34': -0.064,\n",
    "    'age_406': 0.657,\n",
    "    'age_60a': 0.523,    \n",
    "    'educ': 0.313,\n",
    "    'income_5010': 0.368,\n",
    "    'income_100a': 1.075,\n",
    "\n",
    "    \n",
    "\n",
    "}\n",
    "# Example features from validation dataset\n",
    "features = ['gender', 'drv_exp', 'violations', 'benefitfav', 'barrierfav', 'socialfav', 'veh_time','age_34', 'age_406', 'age_60a', 'educ', 'income_5010', 'income_100a']\n",
    "\n",
    "# Define thresholds for the ordinal logistic model\n",
    "thresholds = [-2.064, -0.433, 0.433, 2.064]\n",
    "# Make sure the features in the dataset are the same as those in the 'features' list\n",
    "X_valid = valid_df[features].values\n",
    "\n",
    "# Calculate the linear combination of inputs and beta values (utility)\n",
    "def calculate_utility(X, beta_values, features):\n",
    "    intercept = beta_values['ASC_choice']\n",
    "    beta = np.array([beta_values[feature] for feature in features])\n",
    "    utility = np.dot(X, beta) + intercept\n",
    "    return utility\n",
    "\n",
    "# Calculate the predicted probabilities for each class (categories)\n",
    "def calculate_probabilities(utility, thresholds):\n",
    "    thresholds = [-np.inf] + thresholds + [np.inf]  # Adding extreme thresholds\n",
    "    probabilities = np.zeros((utility.shape[0], len(thresholds) - 1))  # Probability for each category\n",
    "    \n",
    "    # Calculate the probabilities for each category (from 0 to 4 for a 5-point scale)\n",
    "    for i in range(1, len(thresholds)):\n",
    "        probabilities[:, i - 1] = expit(thresholds[i] - utility) - expit(thresholds[i - 1] - utility)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# # Thresholds for the ordinal categories (you can adjust them based on your data)\n",
    "# thresholds = [-2.417, -0.766, 0.766, 2.417]  # Example, modify if needed for your scale\n",
    "\n",
    "# Calculate utility for validation data\n",
    "utility_valid = calculate_utility(X_valid, beta_values, features)\n",
    "\n",
    "# Predict probabilities for each category (5 categories in total)\n",
    "probabilities_valid = calculate_probabilities(utility_valid, thresholds)\n",
    "\n",
    "# Get true class labels from the 'pav_adopt' column\n",
    "true_class = valid_df['FAV_adopt'].values\n",
    "\n",
    "# Check if any true_class values are out of bounds\n",
    "print(\"Unique values in true_class:\", np.unique(true_class))\n",
    "\n",
    "# Ensure true_class values are within the valid range [0, 4] for the 5-point Likert scale\n",
    "true_class = np.clip(true_class, 0, 4)\n",
    "\n",
    "# Calculate the log-likelihood for each observation\n",
    "log_likelihood = np.sum([np.log(probabilities_valid[i, true_class[i]]) for i in range(len(true_class))])\n",
    "\n",
    "# Optionally, multiply the log-likelihood by the number of data points (if necessary)\n",
    "num_data_points = len(valid_df)\n",
    "log_likelihood *= num_data_points\n",
    "\n",
    "print(f\"Total Log-Likelihood for Validation Data (multiplied by number of data points): {log_likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "948d468f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in true_class: [1 2 3 4 5]\n",
      "Total Log-Likelihood for Validation Data (multiplied by number of data points): -7578.712296913909\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_train_data.csv', delimiter=',')\n",
    "valid_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "\n",
    "# Define the beta values as given, excluding delta_u1 and delta_u2\n",
    "beta_values = {\n",
    "    'ASC_choice': -0.301670,\n",
    "    'age_34': -0.158519,\n",
    "    'age_406': -0.113005,\n",
    "    'age_60a': 1.026286,\n",
    "    'barrierfav': 0.322986,\n",
    "    'benefitfav': 0.526285,\n",
    "    'veh_time': 0.426917,\n",
    "    'drv_exp': 0.370264,\n",
    "    'educ': 0.932824,\n",
    "    'gender': -0.405385,\n",
    "    'income_100a': 1.878591,\n",
    "    'income_5010': 0.574125,\n",
    "    'socialfav': 0.166702,\n",
    "    'violations': -0.459699\n",
    "}\n",
    "\n",
    "# Define thresholds for the ordinal logistic model\n",
    "thresholds = [-2.939, -0.782, 0.782, 2.939]\n",
    "# Example features from validation dataset\n",
    "features = ['gender', 'drv_exp', 'violations', 'benefitfav', 'barrierfav', 'socialfav', 'veh_time','age_34', 'age_406', 'age_60a', 'educ', 'income_5010', 'income_100a']\n",
    "\n",
    "# # Define thresholds for the ordinal logistic model\n",
    "# thresholds = [-2.064, -0.433, 0.433, 2.064]\n",
    "# Make sure the features in the dataset are the same as those in the 'features' list\n",
    "X_valid = valid_df[features].values\n",
    "\n",
    "# Calculate the linear combination of inputs and beta values (utility)\n",
    "def calculate_utility(X, beta_values, features):\n",
    "    intercept = beta_values['ASC_choice']\n",
    "    beta = np.array([beta_values[feature] for feature in features])\n",
    "    utility = np.dot(X, beta) + intercept\n",
    "    return utility\n",
    "\n",
    "# Calculate the predicted probabilities for each class (categories)\n",
    "def calculate_probabilities(utility, thresholds):\n",
    "    thresholds = [-np.inf] + thresholds + [np.inf]  # Adding extreme thresholds\n",
    "    probabilities = np.zeros((utility.shape[0], len(thresholds) - 1))  # Probability for each category\n",
    "    \n",
    "    # Calculate the probabilities for each category (from 0 to 4 for a 5-point scale)\n",
    "    for i in range(1, len(thresholds)):\n",
    "        probabilities[:, i - 1] = expit(thresholds[i] - utility) - expit(thresholds[i - 1] - utility)\n",
    "    \n",
    "    return probabilities\n",
    "\n",
    "# # Thresholds for the ordinal categories (you can adjust them based on your data)\n",
    "# thresholds = [-2.417, -0.766, 0.766, 2.417]  # Example, modify if needed for your scale\n",
    "\n",
    "# Calculate utility for validation data\n",
    "utility_valid = calculate_utility(X_valid, beta_values, features)\n",
    "\n",
    "# Predict probabilities for each category (5 categories in total)\n",
    "probabilities_valid = calculate_probabilities(utility_valid, thresholds)\n",
    "\n",
    "# Get true class labels from the 'pav_adopt' column\n",
    "true_class = valid_df['FAV_adopt'].values\n",
    "\n",
    "# Check if any true_class values are out of bounds\n",
    "print(\"Unique values in true_class:\", np.unique(true_class))\n",
    "\n",
    "# Ensure true_class values are within the valid range [0, 4] for the 5-point Likert scale\n",
    "true_class = np.clip(true_class, 0, 4)\n",
    "\n",
    "# Calculate the log-likelihood for each observation\n",
    "log_likelihood = np.sum([np.log(probabilities_valid[i, true_class[i]]) for i in range(len(true_class))])\n",
    "\n",
    "# Optionally, multiply the log-likelihood by the number of data points (if necessary)\n",
    "num_data_points = len(valid_df)\n",
    "log_likelihood *= num_data_points\n",
    "\n",
    "print(f\"Total Log-Likelihood for Validation Data (multiplied by number of data points): {log_likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7974e1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood for Validation Data: -9282.952326608029\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit  # Importing the sigmoid function\n",
    "\n",
    "# Load the datasets\n",
    "# train_df = pd.read_csv('C:/Users/iitrpr/Downloads/fav_train_data.csv', delimiter=',')\n",
    "# valid_df = pd.read_csv('C:/Users/iitrpr/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "valid_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "# Define class-specific beta values\n",
    "beta_values = {\n",
    "    1: {'ASC_choice': 0.407, 'age_34': -0.136, 'age_406': -1.290, 'age_60a': -0.427, 'barrierfav': -0.032, 'benefitfav': -0.818, 'veh_time': 0.017, 'drv_exp': -0.027, 'educ': 0.079, 'gender': -0.188, 'income_100a': 4.207, 'income_5010': 1.469, 'socialfav': -0.549, 'violations': -0.717},\n",
    "    2: {'ASC_choice': 0.476, 'age_34': -0.606, 'age_406': -0.538, 'age_60a': -1.431, 'barrierfav': -0.413, 'benefitfav': 0.200, 'veh_time': 1.648, 'drv_exp': 1.060, 'educ': 1.839, 'gender': -1.436, 'income_100a': 0.536, 'income_5010': 0.291, 'socialfav': -0.113, 'violations': -1.067},\n",
    "    3: {'ASC_choice': -0.236, 'age_34': -0.362, 'age_406': -0.080, 'age_60a': 6.015, 'barrierfav': 0.334, 'benefitfav': 0.821, 'veh_time': 2.073, 'drv_exp': 1.318, 'educ': -0.125, 'gender': -0.403, 'income_100a': 1.541, 'income_5010': 0.571, 'socialfav': 0.226, 'violations': -0.369},\n",
    "    4: {'ASC_choice': 0.332, 'age_34': 1.586, 'age_406': 0.609, 'age_60a': 4.342, 'barrierfav': 1.016, 'benefitfav': 0.334, 'veh_time': -0.254, 'drv_exp': -1.562, 'educ': 1.140, 'gender': -0.576, 'income_100a': 2.452, 'income_5010': 0.191, 'socialfav': 0.439, 'violations': -0.554},\n",
    "    5: {'ASC_choice': 0.681, 'age_34': 0.260, 'age_406': -0.561, 'age_60a': 2.341, 'barrierfav': -0.195, 'benefitfav': -0.771, 'veh_time': 1.690, 'drv_exp': 0.807, 'educ': 0.121, 'gender': -0.763, 'income_100a': -1.527, 'income_5010': -1.036, 'socialfav': -0.392, 'violations': -0.375}\n",
    "}\n",
    "\n",
    "# Extract features and labels from validation data\n",
    "features = list(beta_values[1].keys())\n",
    "features.remove('ASC_choice')  # Remove the constant term from the feature list\n",
    "\n",
    "X_valid = valid_df[features].values\n",
    "y_valid = valid_df['FAV_adopt'].values  # True class labels\n",
    "\n",
    "# Calculate the linear combination of inputs and beta values (utility) for each class\n",
    "def calculate_utility_class(X, beta_values, class_label):\n",
    "    intercept = beta_values[class_label]['ASC_choice']\n",
    "    beta = np.array([beta_values[class_label][feature] for feature in features])\n",
    "    utility = np.dot(X, beta) + intercept\n",
    "    return utility\n",
    "\n",
    "# Calculate the predicted probabilities for each class using softmax\n",
    "def calculate_probabilities_softmax(X, beta_values):\n",
    "    utilities = np.array([calculate_utility_class(X, beta_values, class_label) for class_label in beta_values.keys()])\n",
    "    exp_utilities = np.exp(utilities - np.max(utilities, axis=0))\n",
    "    probabilities = exp_utilities / exp_utilities.sum(axis=0)\n",
    "    return probabilities.T\n",
    "\n",
    "# Predict probabilities for validation data\n",
    "probabilities_valid = calculate_probabilities_softmax(X_valid, beta_values)\n",
    "\n",
    "# Calculate log-likelihood\n",
    "log_likelihood = np.sum(np.log([probabilities_valid[i, y_valid[i] - 1] for i in range(len(y_valid))]))\n",
    "\n",
    "# Multiply by the number of data points (n = 66)\n",
    "n = len(y_valid)\n",
    "log_likelihood *= n\n",
    "\n",
    "print(f\"Log-Likelihood for Validation Data: {log_likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a18b9ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Likelihood for Validation Data: -8526.01235999871\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import expit  # Importing the sigmoid function\n",
    "\n",
    "# Load the datasets\n",
    "train_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_train_data1.csv', delimiter=',')\n",
    "valid_df = pd.read_csv('C:/Users/Administrator/Downloads/fav_valid_data1.csv', delimiter=',')\n",
    "\n",
    "# Define class-specific beta values\n",
    "beta_values = {\n",
    "    1: {'ASC_choice': 0.159, 'age_34': -0.417, 'age_406': -0.896, 'age_60a': -1.129, 'barrier': -0.177, 'benefit': -0.284, 'wtp': -0.181, 'drv_exp': 0.394, 'educ': 0.357, 'gender': -0.265, 'household': 0.435, 'income_100a': 0.765, 'income_5010': 0.755, 'safety': 0.467, 'violations': -0.162},\n",
    "    2: {'ASC_choice': 0.206, 'age_34': 0.300, 'age_406': -0.575, 'age_60a': -0.697, 'barrier': -0.045, 'benefit': -0.220, 'wtp': 0.165, 'drv_exp': 0.085, 'educ': 0.668, 'gender': -0.951, 'household': -0.113, 'income_100a': 1.126, 'income_5010': 0.676, 'safety': 0.152, 'violations': -0.219},\n",
    "    3: {'ASC_choice': -0.083, 'age_34': 0.279, 'age_406': 0.275, 'age_60a': 0.621, 'barrier': 0.258, 'benefit': 0.382, 'wtp': 0.621, 'drv_exp': -0.392, 'educ': -0.443, 'gender': 0.649, 'household': -0.086, 'income_100a': 1.516, 'income_5010': -0.041, 'safety': 0.218, 'violations': -0.228},\n",
    "    4: {'ASC_choice': 0.089, 'age_34': -0.899, 'age_406': -0.839, 'age_60a': -0.739, 'barrier': 0.003, 'benefit': 0.353, 'wtp': 0.580, 'drv_exp': 1.075, 'educ': 0.536, 'gender': -0.043, 'household': 0.279, 'income_100a': -0.120, 'income_5010': 0.454, 'safety': -0.348, 'violations': 0.002},\n",
    "    5: {'ASC_choice': 0.164, 'age_34': -0.147, 'age_406': 0.010, 'age_60a': -0.253, 'barrier': -0.783, 'benefit': 0.159, 'wtp': -0.433, 'drv_exp': -0.095, 'educ': 0.079, 'gender': -0.375, 'household': 0.280, 'income_100a': 0.602, 'income_5010': 0.720, 'safety': -0.150, 'violations': 0.359}\n",
    "}\n",
    "\n",
    "# Define thresholds for the ordinal logistic model\n",
    "thresholds = [4.501, 2.882, 0.543, -1.112]\n",
    "# Extract features and labels from validation data\n",
    "features = list(beta_values[1].keys())\n",
    "features.remove('ASC_choice')  # Remove the constant term from the feature list\n",
    "\n",
    "X_valid = valid_df[features].values\n",
    "y_valid = valid_df['pav_adopt'].values  # True class labels\n",
    "\n",
    "# Calculate the linear combination of inputs and beta values (utility) for each class\n",
    "def calculate_utility_class(X, beta_values, class_label):\n",
    "    intercept = beta_values[class_label]['ASC_choice']\n",
    "    beta = np.array([beta_values[class_label][feature] for feature in features])\n",
    "    utility = np.dot(X, beta) + intercept\n",
    "    return utility\n",
    "\n",
    "# Calculate the predicted probabilities for each class using softmax\n",
    "def calculate_probabilities_softmax(X, beta_values):\n",
    "    utilities = np.array([calculate_utility_class(X, beta_values, class_label) for class_label in beta_values.keys()])\n",
    "    exp_utilities = np.exp(utilities - np.max(utilities, axis=0))\n",
    "    probabilities = exp_utilities / exp_utilities.sum(axis=0)\n",
    "    return probabilities.T\n",
    "\n",
    "# Predict probabilities for validation data\n",
    "probabilities_valid = calculate_probabilities_softmax(X_valid, beta_values)\n",
    "\n",
    "# Calculate log-likelihood\n",
    "log_likelihood = np.sum(np.log([probabilities_valid[i, y_valid[i] - 1] for i in range(len(y_valid))]))\n",
    "\n",
    "# Multiply by the number of data points (n = 66)\n",
    "n = len(y_valid)\n",
    "log_likelihood *= n\n",
    "\n",
    "print(f\"Log-Likelihood for Validation Data: {log_likelihood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98013c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shelve\n",
    "import _pickle as pickle\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import TensorBoard, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.layers import Input, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, Add, Reshape\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "#from keras.utils.vis_utils import plot_model\n",
    "#from keras.utils import np_utils\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping\n",
    "model_inputs = [agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau]\n",
    "data_size = len(model_inputs[0])\n",
    "betas_layer1 = model.get_layer(name = 'gendera')\n",
    "betas_layer2 = model.get_layer(name = 'drv_expa')\n",
    "betas_layer3 = model.get_layer(name = 'violationa')\n",
    "betas_layer4 = model.get_layer(name = 'wtpa')\n",
    "betas_layer5 = model.get_layer(name = 'benefita')\n",
    "betas_layer6 = model.get_layer(name = 'barriera')\n",
    "betas_layer7 = model.get_layer(name = 'safetya')\n",
    "betas_layer8 = model.get_layer(name = 'age_34a')\n",
    "# betas_layer9 = model.get_layer(name = 'age_44a')\n",
    "betas_layer10 = model.get_layer(name = 'age_406aa')\n",
    "betas_layer11 = model.get_layer(name = 'age_60aaa')\n",
    "betas_layer12 = model.get_layer(name = 'educa')\n",
    "betas_layer13 = model.get_layer(name = 'income_5010a')\n",
    "# betas_layer14 = model.get_layer(name = 'income_50a')\n",
    "# betas_layer15 = model.get_layer(name = 'income_100aa')\n",
    "betas_layer16 = model.get_layer(name = 'income_100aaa')\n",
    "betas_layer17 = model.get_layer(name = 'householda')\n",
    "# betas_layer18 = model.get_layer(name = 'occua')\n",
    "betas_layer19 = model.get_layer(name = 'ASCa1')\n",
    "betas_layer20 = model.get_layer(name = 'ttau1a')\n",
    "betas_layer21 = model.get_layer(name = 'ttau3a')\n",
    "label=train_labels\n",
    "# label = train_labels_one_hot\n",
    "with tf.GradientTape() as g:\n",
    "    with tf.GradientTape() as g1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "#             print(f\"Shape of labels: {labels.shape}\")\n",
    "#             print(f\"Shape of pred before squeeze: {pred.shape}\")\n",
    "# #             pred = tf.squeeze(pred, axis=-1)\n",
    "#             print(f\"Shape of pred after squeeze: {pred.shape}\")\n",
    "\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1 = g1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op1 = g.jacobian(beta_gradient1, betas_layer1.weights[0])\n",
    "with tf.GradientTape() as h:\n",
    "    with tf.GradientTape() as h1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2 = h1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op2 = h.jacobian(beta_gradient2, betas_layer2.weights[0])\n",
    "\n",
    "with tf.GradientTape() as i:\n",
    "    with tf.GradientTape() as i1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient3 = i1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op3 = i.jacobian(beta_gradient3, betas_layer3.weights[0])\n",
    "\n",
    "with tf.GradientTape() as j:\n",
    "    with tf.GradientTape() as j1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient4 = j1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op4 = j.jacobian(beta_gradient4, betas_layer4.weights[0])\n",
    "\n",
    "with tf.GradientTape() as k:\n",
    "    with tf.GradientTape() as k1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)       \n",
    "    beta_gradient5 = k1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op5 = k.jacobian(beta_gradient5, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as l:\n",
    "    with tf.GradientTape() as l1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)     \n",
    "    beta_gradient6 = l1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op6 = l.jacobian(beta_gradient6, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as n:\n",
    "    with tf.GradientTape() as n1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient7 = n1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op7 = n.jacobian(beta_gradient7, betas_layer7.weights[0])\n",
    "\n",
    "with tf.GradientTape() as m:\n",
    "    with tf.GradientTape() as m1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient8 = m1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op8 = m.jacobian(beta_gradient8, betas_layer8.weights[0])\n",
    "\n",
    "with tf.GradientTape() as o:\n",
    "    with tf.GradientTape() as o1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradienta10 = o1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_opa10 = o.jacobian(beta_gradienta10, betas_layer10.weights[0])\n",
    "\n",
    "with tf.GradientTape() as q:\n",
    "    with tf.GradientTape() as q1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)            \n",
    "    beta_gradienta11 = q1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_opa11 = q.jacobian(beta_gradienta11, betas_layer11.weights[0])\n",
    "\n",
    "with tf.GradientTape() as p:\n",
    "    with tf.GradientTape() as p1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)    \n",
    "    beta_gradienta12 = p1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_opa12 = p.jacobian(beta_gradienta12, betas_layer12.weights[0])\n",
    "\n",
    "with tf.GradientTape() as s:\n",
    "    with tf.GradientTape() as s1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)       \n",
    "    beta_gradienta13 = s1.gradient(loss, betas_layer13.weights[0])[0]\n",
    "Hessian_lines_opa13 = s.jacobian(beta_gradienta13, betas_layer13.weights[0])\n",
    "\n",
    "with tf.GradientTape() as u:\n",
    "    with tf.GradientTape() as u1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)      \n",
    "    beta_gradienta16 = u1.gradient(loss, betas_layer16.weights[0])[0]\n",
    "Hessian_lines_opa16 = u.jacobian(beta_gradienta16, betas_layer16.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ukq:\n",
    "    with tf.GradientTape() as ukq1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)      \n",
    "    beta_gradienta16q = ukq1.gradient(loss, betas_layer17.weights[0])[0]\n",
    "Hessian_lines_opa17 = ukq.jacobian(beta_gradienta16q, betas_layer17.weights[0])\n",
    "\n",
    "with tf.GradientTape() as w:\n",
    "    with tf.GradientTape() as w1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)        \n",
    "    beta_gradienta19 = w1.gradient(loss, betas_layer19.weights[0])[0]\n",
    "Hessian_lines_opa19 = w.jacobian(beta_gradienta19, betas_layer19.weights[0])\n",
    "\n",
    "with tf.GradientTape() as t:\n",
    "    with tf.GradientTape() as t1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient6a = t1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op12= t.jacobian(beta_gradient6a, betas_layer2.weights[0])\n",
    "\n",
    "with tf.GradientTape() as v:\n",
    "    with tf.GradientTape() as v1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient7a = v1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op13= v.jacobian(beta_gradient7a, betas_layer3.weights[0])\n",
    "\n",
    "with tf.GradientTape() as x:\n",
    "    with tf.GradientTape() as x1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient8a = x1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op23= x.jacobian(beta_gradient8a, betas_layer3.weights[0])\n",
    "\n",
    "with tf.GradientTape() as z:\n",
    "    with tf.GradientTape() as z1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient9a = z1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op14= z.jacobian(beta_gradient9a, betas_layer4.weights[0])\n",
    "\n",
    "with tf.GradientTape() as qa:\n",
    "    with tf.GradientTape() as qa1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient10b = qa1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op24= qa.jacobian(beta_gradient10b, betas_layer4.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ra:\n",
    "    with tf.GradientTape() as ra1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient11b = ra1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op34= ra.jacobian(beta_gradient11b, betas_layer4.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sa:\n",
    "    with tf.GradientTape() as sa1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient12b = sa1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op15= sa.jacobian(beta_gradient12b, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ta:\n",
    "    with tf.GradientTape() as ta1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient13b = ta1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op25= ta.jacobian(beta_gradient13b, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ua:\n",
    "    with tf.GradientTape() as ua1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient14b = ua1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op35= ua.jacobian(beta_gradient14b, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sb:\n",
    "    with tf.GradientTape() as sb1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15b = sb1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op45= sb.jacobian(beta_gradient15b, betas_layer5.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sc:\n",
    "    with tf.GradientTape() as sc1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient16b = sc1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op16= sc.jacobian(beta_gradient16b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sd:\n",
    "    with tf.GradientTape() as sd1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient17b = sd1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op26= sd.jacobian(beta_gradient17b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as se:\n",
    "    with tf.GradientTape() as se1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient18b = se1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op36= se.jacobian(beta_gradient18b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sf:\n",
    "    with tf.GradientTape() as sf1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient19b = sf1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op46= sf.jacobian(beta_gradient19b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sg:\n",
    "    with tf.GradientTape() as sg1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient20b = sg1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op56= sg.jacobian(beta_gradient20b, betas_layer6.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sh:\n",
    "    with tf.GradientTape() as sh1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15c = sh1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op17= sh.jacobian(beta_gradient15c, betas_layer7.weights[0])\n",
    "with tf.GradientTape() as si:\n",
    "    with tf.GradientTape() as si1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient16c = si1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op27= si.jacobian(beta_gradient16c, betas_layer7.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sj:\n",
    "    with tf.GradientTape() as sj1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15ba = sj1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op37= sj.jacobian(beta_gradient15ba, betas_layer7.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sk:\n",
    "    with tf.GradientTape() as sk1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15bc = sk1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op47= sk.jacobian(beta_gradient15bc, betas_layer7.weights[0])\n",
    "with tf.GradientTape() as sl:\n",
    "    with tf.GradientTape() as sl1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15bv = sl1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op57= sl.jacobian(beta_gradient15bv, betas_layer7.weights[0])\n",
    "with tf.GradientTape() as sm:\n",
    "    with tf.GradientTape() as sm1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15bq = sm1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op67= sm.jacobian(beta_gradient15bq, betas_layer7.weights[0])\n",
    "with tf.GradientTape() as sn:\n",
    "    with tf.GradientTape() as sn1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15ca = sn1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op18= sn.jacobian(beta_gradient15ca, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as so:\n",
    "    with tf.GradientTape() as so1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient12b = so1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op28= so.jacobian(beta_gradient12b, betas_layer8.weights[0])\n",
    "\n",
    "with tf.GradientTape() as sp:\n",
    "    with tf.GradientTape() as sp1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient115b = sp1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op38= sp.jacobian(beta_gradient115b, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as sq:\n",
    "    with tf.GradientTape() as sq1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient151b = sq1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op48= sq.jacobian(beta_gradient151b, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as sr:\n",
    "    with tf.GradientTape() as sr1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient11bk = sr1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op58= sr.jacobian(beta_gradient11bk, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as ss:\n",
    "    with tf.GradientTape() as ss1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient11cb = ss1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op68= ss.jacobian(beta_gradient11cb, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as st:\n",
    "    with tf.GradientTape() as st1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient111cb = st1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op78= st.jacobian(beta_gradient111cb, betas_layer8.weights[0])\n",
    "with tf.GradientTape() as su:\n",
    "    with tf.GradientTape() as su1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient112cb = su1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op110= su.jacobian(beta_gradient112cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sv:\n",
    "    with tf.GradientTape() as sv1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient113cb = sv1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op210= sv.jacobian(beta_gradient113cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sw:\n",
    "    with tf.GradientTape() as sw1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient114cb = sw1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op310= sw.jacobian(beta_gradient114cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sx:\n",
    "    with tf.GradientTape() as sx1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient115cb = sx1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op410= sx.jacobian(beta_gradient115cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sy:\n",
    "    with tf.GradientTape() as sy1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient116cb = sy1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op510= sy.jacobian(beta_gradient116cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as sz:\n",
    "    with tf.GradientTape() as sz1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient117cb = sz1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op610= sz.jacobian(beta_gradient117cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as s1:\n",
    "    with tf.GradientTape() as s11:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "            \n",
    "    beta_gradient118cb = s11.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op710= s1.jacobian(beta_gradient118cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as s2:\n",
    "    with tf.GradientTape() as s21:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "            \n",
    "    beta_gradient119cb = s21.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op810= s2.jacobian(beta_gradient119cb, betas_layer10.weights[0])\n",
    "with tf.GradientTape() as s3:\n",
    "    with tf.GradientTape() as s13:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient211cb = s13.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op111= s3.jacobian(beta_gradient211cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s4:\n",
    "    with tf.GradientTape() as s14:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient311cb = s14.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op211= s4.jacobian(beta_gradient311cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s5:\n",
    "    with tf.GradientTape() as s15:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient411cb = s15.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op311= s5.jacobian(beta_gradient411cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s6:\n",
    "    with tf.GradientTape() as s16:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient511cb = s16.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op411= s6.jacobian(beta_gradient511cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s7:\n",
    "    with tf.GradientTape() as s17:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient611cb = s17.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op511= s7.jacobian(beta_gradient611cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s8:\n",
    "    with tf.GradientTape() as s18:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient711cb = s18.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op611= s8.jacobian(beta_gradient711cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as s9:\n",
    "    with tf.GradientTape() as s19:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient811cb = s19.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op711= s9.jacobian(beta_gradient811cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as a1:\n",
    "    with tf.GradientTape() as a111:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient911cb = a111.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op811= a1.jacobian(beta_gradient911cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as b:\n",
    "    with tf.GradientTape() as bb1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1011cb = bb1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1011= b.jacobian(beta_gradient1011cb, betas_layer11.weights[0])\n",
    "with tf.GradientTape() as cc:\n",
    "    with tf.GradientTape() as cc1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1111cb = cc1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op112= cc.jacobian(beta_gradient1111cb, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as dd:\n",
    "    with tf.GradientTape() as dd1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1211cb = dd1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op212= dd.jacobian(beta_gradient1211cb, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as ee:\n",
    "    with tf.GradientTape() as ee1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1311cb = ee1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op312= ee.jacobian(beta_gradient1311cb, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as ff:\n",
    "    with tf.GradientTape() as ff1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient1lp = ff1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op412= ff.jacobian(beta_gradient1lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as gg:\n",
    "    with tf.GradientTape() as gg1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2lp = gg1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op512= gg.jacobian(beta_gradient2lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as hh:\n",
    "    with tf.GradientTape() as hh1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient3lp = hh1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op612= hh.jacobian(beta_gradient3lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as ii:\n",
    "    with tf.GradientTape() as ii1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient4lp = ii1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op712= ii.jacobian(beta_gradient4lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as sjj:\n",
    "    with tf.GradientTape() as sjj1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient5lp = sjj1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op812= sjj.jacobian(beta_gradient5lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as skk:\n",
    "    with tf.GradientTape() as skk1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient6lp = skk1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1012= skk.jacobian(beta_gradient6lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as sll:\n",
    "    with tf.GradientTape() as sll1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient7lp = sll1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1112= sll.jacobian(beta_gradient7lp, betas_layer12.weights[0])\n",
    "with tf.GradientTape() as smm:\n",
    "    with tf.GradientTape() as smm1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient8lp = smm1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op113= smm.jacobian(beta_gradient8lp, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as snn:\n",
    "    with tf.GradientTape() as snn1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient9lp = snn1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op213= snn.jacobian(beta_gradient9lp, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as spp:\n",
    "    with tf.GradientTape() as spp1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient10lp = spp1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op313= spp.jacobian(beta_gradient10lp, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as sqq:\n",
    "    with tf.GradientTape() as sqq1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient11lp = sqq1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op413= sqq.jacobian(beta_gradient11lp, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as srr:\n",
    "    with tf.GradientTape() as srr1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient12lq = srr1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op513= srr.jacobian(beta_gradient12lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as stt:\n",
    "    with tf.GradientTape() as stt1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient13lq = stt1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op613= stt.jacobian(beta_gradient13lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as suu:\n",
    "    with tf.GradientTape() as suu1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient14lq = suu1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op713= suu.jacobian(beta_gradient14lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as suu2:\n",
    "    with tf.GradientTape() as suu3:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient15lq = suu3.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op813= suu2.jacobian(beta_gradient15lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as svv:\n",
    "    with tf.GradientTape() as svv1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient16lq = svv1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1013= svv.jacobian(beta_gradient16lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as stt:\n",
    "    with tf.GradientTape() as stt1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient17lq = stt1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1113= stt.jacobian(beta_gradient17lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as sxx:\n",
    "    with tf.GradientTape() as sxx1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient18lq = sxx1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_op1213= sxx.jacobian(beta_gradient18lq, betas_layer13.weights[0])\n",
    "with tf.GradientTape() as syy:\n",
    "    with tf.GradientTape() as syy1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient19lq = syy1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op116= syy.jacobian(beta_gradient19lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as szz:\n",
    "    with tf.GradientTape() as szz1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient20lq = szz1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op216= szz.jacobian(beta_gradient20lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as zzs:\n",
    "    with tf.GradientTape() as zzs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient21lq = zzs1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op316= zzs.jacobian(beta_gradient21lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as yys:\n",
    "    with tf.GradientTape() as yys1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient212lq = yys1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op416= yys.jacobian(beta_gradient212lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as xxs:\n",
    "    with tf.GradientTape() as xxs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient213lq = xxs1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op516= xxs.jacobian(beta_gradient213lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as uus:\n",
    "    with tf.GradientTape() as uus1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient214lq = uus1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op616= uus.jacobian(beta_gradient214lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as vvs:\n",
    "    with tf.GradientTape() as vvs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient215lq = vvs1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op716= vvs.jacobian(beta_gradient215lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as ccs:\n",
    "    with tf.GradientTape() as ccs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient216lq = ccs1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op816= ccs.jacobian(beta_gradient216lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as dds:\n",
    "    with tf.GradientTape() as dds1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient271lq = dds1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1016= dds.jacobian(beta_gradient271lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as ees:\n",
    "    with tf.GradientTape() as ees1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient218lq = ees1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1116= ees.jacobian(beta_gradient218lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as ffs:\n",
    "    with tf.GradientTape() as ffs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient219lq = ffs1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_op1216= ffs.jacobian(beta_gradient219lq, betas_layer16.weights[0])\n",
    "with tf.GradientTape() as ggs:\n",
    "    with tf.GradientTape() as ggs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2120lq = ggs1.gradient(loss, betas_layer13.weights[0])[0]\n",
    "Hessian_lines_op1316= ggs.jacobian(beta_gradient2120lq, betas_layer16.weights[0])\n",
    "\n",
    "with tf.GradientTape() as ggsp:\n",
    "    with tf.GradientTape() as ggsp1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2120lqg = ggsp1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op117= ggsp.jacobian(beta_gradient2120lqg, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as ggs11:\n",
    "    with tf.GradientTape() as ggs111:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2120lq1 = ggs111.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op217= ggs11.jacobian(beta_gradient2120lq1, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnl:\n",
    "    with tf.GradientTape() as nnl1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient7190lqn = nnl1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op317= nnl.jacobian(beta_gradient7190lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnla:\n",
    "    with tf.GradientTape() as nnla1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71901lqn = nnla1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op417= nnla.jacobian(beta_gradient71901lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlb:\n",
    "    with tf.GradientTape() as nnlb1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71902lqn = nnlb1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op517= nnlb.jacobian(beta_gradient71902lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlc:\n",
    "    with tf.GradientTape() as nnlc1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71903lqn = nnlc1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op617= nnlc.jacobian(beta_gradient71903lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnld:\n",
    "    with tf.GradientTape() as nnld1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71904lqn = nnld1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op717= nnld.jacobian(beta_gradient71904lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnle:\n",
    "    with tf.GradientTape() as nnle1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71905lqn = nnle1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op817= nnle.jacobian(beta_gradient71905lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlf:\n",
    "    with tf.GradientTape() as nnlf1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71906lqn = nnlf1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1017= nnlf.jacobian(beta_gradient71906lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlg:\n",
    "    with tf.GradientTape() as nnlg1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71907lqn = nnlg1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1117= nnlg.jacobian(beta_gradient71907lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlh:\n",
    "    with tf.GradientTape() as nnlh1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71908lqn = nnlh1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_op1217= nnlh.jacobian(beta_gradient71908lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnli:\n",
    "    with tf.GradientTape() as nnli1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient71909lqn = nnli1.gradient(loss, betas_layer13.weights[0])[0]\n",
    "Hessian_lines_op1317= nnli.jacobian(beta_gradient71909lqn, betas_layer17.weights[0])\n",
    "with tf.GradientTape() as nnlha:\n",
    "    with tf.GradientTape() as nnlha1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient719011lqn = nnlha1.gradient(loss, betas_layer16.weights[0])[0]\n",
    "Hessian_lines_op1617= nnlha.jacobian(beta_gradient719011lqn, betas_layer17.weights[0])\n",
    "\n",
    "with tf.GradientTape() as hhs:\n",
    "    with tf.GradientTape() as hhs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2121lq = hhs1.gradient(loss, betas_layer1.weights[0])[0]\n",
    "Hessian_lines_op119= hhs.jacobian(beta_gradient2121lq, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as jjs:\n",
    "    with tf.GradientTape() as jjs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient21vu = jjs1.gradient(loss, betas_layer2.weights[0])[0]\n",
    "Hessian_lines_op219= jjs.jacobian(beta_gradient21vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as kks:\n",
    "    with tf.GradientTape() as kks1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient212vu = kks1.gradient(loss, betas_layer3.weights[0])[0]\n",
    "Hessian_lines_op319= kks.jacobian(beta_gradient212vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as mms:\n",
    "    with tf.GradientTape() as mms1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient213vu = mms1.gradient(loss, betas_layer4.weights[0])[0]\n",
    "Hessian_lines_op419= mms.jacobian(beta_gradient213vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as nns:\n",
    "    with tf.GradientTape() as nns1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient214vu = nns1.gradient(loss, betas_layer5.weights[0])[0]\n",
    "Hessian_lines_op519= nns.jacobian(beta_gradient214vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as pps:\n",
    "    with tf.GradientTape() as pps1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient215vu = pps1.gradient(loss, betas_layer6.weights[0])[0]\n",
    "Hessian_lines_op619= pps.jacobian(beta_gradient215vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as rrs:\n",
    "    with tf.GradientTape() as rrs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient216vu = rrs1.gradient(loss, betas_layer7.weights[0])[0]\n",
    "Hessian_lines_op719= rrs.jacobian(beta_gradient216vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as uus:\n",
    "    with tf.GradientTape() as uus1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient217vu = uus1.gradient(loss, betas_layer8.weights[0])[0]\n",
    "Hessian_lines_op819= uus.jacobian(beta_gradient217vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as aaas:\n",
    "    with tf.GradientTape() as aaas1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient218vu = aaas1.gradient(loss, betas_layer10.weights[0])[0]\n",
    "Hessian_lines_op1019= aaas.jacobian(beta_gradient218vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as bbbs:\n",
    "    with tf.GradientTape() as bbbs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient219vu = bbbs1.gradient(loss, betas_layer11.weights[0])[0]\n",
    "Hessian_lines_op1119= bbbs.jacobian(beta_gradient219vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as cccs:\n",
    "    with tf.GradientTape() as cccs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2120vu = cccs1.gradient(loss, betas_layer12.weights[0])[0]\n",
    "Hessian_lines_op1219= cccs.jacobian(beta_gradient2120vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as ddds:\n",
    "    with tf.GradientTape() as ddds1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2121vu = ddds1.gradient(loss, betas_layer13.weights[0])[0]\n",
    "Hessian_lines_op1319= ddds.jacobian(beta_gradient2121vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as fffs:\n",
    "    with tf.GradientTape() as fffs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2122vu = fffs1.gradient(loss, betas_layer16.weights[0])[0]\n",
    "Hessian_lines_op1619= fffs.jacobian(beta_gradient2122vu, betas_layer19.weights[0])\n",
    "with tf.GradientTape() as gggs:\n",
    "    with tf.GradientTape() as gggs1:\n",
    "        labels = tf.convert_to_tensor(label)\n",
    "        pred = model([agender, adrv_exp, aviolation, awtp,abenefit, abarrier, asafety, aage_34, aage_406, aage_60a, aeduc, aincome_5010, aincome_100a, ahousehold, AASC1, hhet1, ttau, ttau])\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy()(labels,pred)\n",
    "    beta_gradient2123vu = gggs1.gradient(loss, betas_layer17.weights[0])[0]\n",
    "Hessian_lines_op1719= gggs.jacobian(beta_gradient2123vu, betas_layer19.weights[0])\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Hessian1= ([[Hessian_lines_op1, Hessian_lines_op12, Hessian_lines_op13,Hessian_lines_op14,Hessian_lines_op15,Hessian_lines_op16,Hessian_lines_op17,Hessian_lines_op18,Hessian_lines_op110,Hessian_lines_op111,Hessian_lines_op112,Hessian_lines_op113,Hessian_lines_op116,Hessian_lines_op117,Hessian_lines_op119], \n",
    "            [Hessian_lines_op12, Hessian_lines_op2,Hessian_lines_op23,Hessian_lines_op24,Hessian_lines_op25,Hessian_lines_op26,Hessian_lines_op27,Hessian_lines_op28,Hessian_lines_op210,Hessian_lines_op211,Hessian_lines_op212,Hessian_lines_op213,Hessian_lines_op216,Hessian_lines_op217,Hessian_lines_op219],\n",
    "            [Hessian_lines_op13, Hessian_lines_op23,Hessian_lines_op3, Hessian_lines_op34, Hessian_lines_op35, Hessian_lines_op36, Hessian_lines_op37, Hessian_lines_op38, Hessian_lines_op310, Hessian_lines_op311, Hessian_lines_op312, Hessian_lines_op313, Hessian_lines_op316,Hessian_lines_op317, Hessian_lines_op319], \n",
    "            [Hessian_lines_op14, Hessian_lines_op24,Hessian_lines_op34, Hessian_lines_op4, Hessian_lines_op45, Hessian_lines_op46, Hessian_lines_op47, Hessian_lines_op48, Hessian_lines_op410, Hessian_lines_op411, Hessian_lines_op412, Hessian_lines_op413, Hessian_lines_op416,Hessian_lines_op417, Hessian_lines_op419],\n",
    "            [Hessian_lines_op15, Hessian_lines_op25,Hessian_lines_op35, Hessian_lines_op45, Hessian_lines_op5, Hessian_lines_op56, Hessian_lines_op57, Hessian_lines_op58, Hessian_lines_op510, Hessian_lines_op511, Hessian_lines_op512, Hessian_lines_op513, Hessian_lines_op516, Hessian_lines_op517,Hessian_lines_op519],\n",
    "           [Hessian_lines_op16, Hessian_lines_op26,Hessian_lines_op36, Hessian_lines_op46, Hessian_lines_op56, Hessian_lines_op6, Hessian_lines_op67, Hessian_lines_op68, Hessian_lines_op610, Hessian_lines_op611, Hessian_lines_op612, Hessian_lines_op613, Hessian_lines_op616, Hessian_lines_op617,Hessian_lines_op619],\n",
    "           [Hessian_lines_op17, Hessian_lines_op27,Hessian_lines_op37, Hessian_lines_op47, Hessian_lines_op57, Hessian_lines_op67, Hessian_lines_op7, Hessian_lines_op78, Hessian_lines_op710, Hessian_lines_op711, Hessian_lines_op712, Hessian_lines_op713, Hessian_lines_op716, Hessian_lines_op717,Hessian_lines_op719],\n",
    "           [Hessian_lines_op18, Hessian_lines_op28,Hessian_lines_op38, Hessian_lines_op48, Hessian_lines_op58, Hessian_lines_op68, Hessian_lines_op78, Hessian_lines_op8, Hessian_lines_op810, Hessian_lines_op811, Hessian_lines_op812, Hessian_lines_op813, Hessian_lines_op816, Hessian_lines_op817,Hessian_lines_op819],\n",
    "           [Hessian_lines_op110, Hessian_lines_op210,Hessian_lines_op310, Hessian_lines_op410, Hessian_lines_op510, Hessian_lines_op610, Hessian_lines_op710, Hessian_lines_op810, Hessian_lines_opa10, Hessian_lines_op1011, Hessian_lines_op1012, Hessian_lines_op1013, Hessian_lines_op1016,Hessian_lines_op1017, Hessian_lines_op1019],\n",
    "           [Hessian_lines_op111, Hessian_lines_op211,Hessian_lines_op311, Hessian_lines_op411, Hessian_lines_op511, Hessian_lines_op611, Hessian_lines_op711, Hessian_lines_op811, Hessian_lines_op1011, Hessian_lines_opa11, Hessian_lines_op1112, Hessian_lines_op1113, Hessian_lines_op1116, Hessian_lines_op1117,Hessian_lines_op1119],\n",
    "           [Hessian_lines_op112, Hessian_lines_op212,Hessian_lines_op312, Hessian_lines_op412, Hessian_lines_op512, Hessian_lines_op612, Hessian_lines_op712, Hessian_lines_op812, Hessian_lines_op1012, Hessian_lines_op1112, Hessian_lines_opa12, Hessian_lines_op1213, Hessian_lines_op1216, Hessian_lines_op1217,Hessian_lines_op1219],\n",
    "           [Hessian_lines_op113, Hessian_lines_op213,Hessian_lines_op313, Hessian_lines_op413, Hessian_lines_op513, Hessian_lines_op613, Hessian_lines_op713, Hessian_lines_op813, Hessian_lines_op1013, Hessian_lines_op1113, Hessian_lines_op1213, Hessian_lines_opa13, Hessian_lines_op1316, Hessian_lines_op1317,Hessian_lines_op1319],\n",
    "           [Hessian_lines_op116, Hessian_lines_op216,Hessian_lines_op316, Hessian_lines_op416, Hessian_lines_op516, Hessian_lines_op616, Hessian_lines_op716, Hessian_lines_op816, Hessian_lines_op1016, Hessian_lines_op1116, Hessian_lines_op1216, Hessian_lines_op1316, Hessian_lines_opa16, Hessian_lines_op1617,Hessian_lines_op1619],\n",
    "            [Hessian_lines_op117, Hessian_lines_op217,Hessian_lines_op317, Hessian_lines_op417, Hessian_lines_op517, Hessian_lines_op617, Hessian_lines_op717, Hessian_lines_op817, Hessian_lines_op1017, Hessian_lines_op1117, Hessian_lines_op1217, Hessian_lines_op1317, Hessian_lines_op1617, Hessian_lines_opa17,Hessian_lines_op1719],\n",
    "           [Hessian_lines_op119, Hessian_lines_op219,Hessian_lines_op319, Hessian_lines_op419, Hessian_lines_op519, Hessian_lines_op619, Hessian_lines_op719, Hessian_lines_op819, Hessian_lines_op1019, Hessian_lines_op1119, Hessian_lines_op1219, Hessian_lines_op1319, Hessian_lines_op1619, Hessian_lines_op1719,Hessian_lines_opa19]])\n",
    "Hessian = np.squeeze(Hessian1)*data_size\n",
    "invHess = np.linalg.inv(Hessian)\n",
    "\n",
    "# Extract the diagonal elements\n",
    "diagonal_elements = np.diag(invHess)\n",
    "\n",
    "# Compute standard errors\n",
    "standard_errors = np.sqrt(diagonal_elements)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
